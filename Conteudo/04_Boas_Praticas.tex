\chapter{Boas práticas}\label{chapter-boas-praticas}

\chapterprecis{Este capítulo aprensenta as boas práticas comumente seguidas na construção de aplicações com arquitetura de microsserviços.}\index{sinopse de capítulo}

\section{Antes de tudo, comece pelo monólito}

\begin{citacao}
But as with any architectural decision there are trade-offs. In particular with microservices there are serious consequences for operations, who now have to handle an ecosystem of small services rather than a single, well-defined monolith. Consequently if you don't have certain baseline competencies, you shouldn't consider using the microservice style. \cite{MartinFowlerMicroservices}
\end{citacao}

\citeonline{MartinFowlerMicroservices} afirma que existem 3 pré-requisitos para se adotar uma arquitetura de microserviços, e que é mais fácil lidar com as operações de um monólito bem definido do que de um ecossistema de pequenos serviços. Assim sendo, é uma boa prática começar pela arquitetura monolítica até que o sistema já esteja bem definido e estes pré-requisitos sejam atendidos - provisionamento rápido, monitoramento básico, e implantação rápida de aplicação.

Já \cite{monolith-or-microservices} concorda com a convenção de começar pelo monólito, mas afirma que podem existir exceções. Ele descreve 3 condições que podem tornar a adoção de uma arquitetura de microserviços em uma nova aplicação a escolha correta. Elas são: Há necessidade de entrega de serviços rapida e independentemente, parte da plataforma precisa ser extremamente eficiente, e planeja-se aumentar o time.

\subsection{Provisionamento rápido}

No contexto da computação, provisionamento significa disponibilizar um recurso, como uma máquina virtual por exemplo. Para produzir software, é necessário provisionar muitos recursos, tanto para os desenvolvedores quanto para o cliente. Naturalmente, o provisionamento é mais fácil na núvem. Na AWS por exemplo, para conseguir uma nova máquina, basta lançar uma nova instância e acessá-la - um processo muito rápido quando comparado ao \emph{on-premises}, onde precisaria-se comprar uma nova máquina, esperar chegar, configurá-la, e só então ela estará pronta. Para alcançar um provisionamento rápido, será necessário bastante automação. \cite{MartinFowlerMicroservices}

\subsection{Monitoramento básico}

Muitas coisas podem dar errado em qualquer tipo de arquitetura, mas em especial nos microserviços pois cada serviço é fracamente acoplado, estando sujeitos não só a falhas no código, mas também na comunicação, na conexão, ou até falhas físicas. Portanto o monitoramento é crucial nesse tipo de arquitetura para que problemas, especialmente os mais graves possam ser detectados no menor tempo possível. Além disso, o monitoramento também pode ser usado para detectar problemas de negócio, como uma redução nos pedidos de um site de vendas, por exemplo. \cite{MartinFowlerMicroservices}

\subsection{Implantação rápida}

Na arquitetura de microserviços a implantação geralmente é feita separadamente para cada microserviço. Com muitos serviços para gerenciar, ela pode se tornar uma tarefa árdua, portanto será novamente necessário uma automação dessa etapa, que geralmente envolve um \emph{pipeline} de implantação, que deve ser automatizado o máximo possível. \cite{MartinFowlerMicroservices}

\section{Implantação}

Automação.

\section{Comunicação entre microserviços}

De acordo com \citeonline{design-monitoring-testing-waseem}, API Gateway e \emph{Backend for frontend} são os padrões de projeto mais utilizados para lidar com a comunicação dos microsserviços. Eles são padrões similares - a diferença é que no \emph{Backend for Frontend} há um \emph{gateway} para cada tipo de cliente. RPC também pode ser utilizado em conjunto com APIs para auxiliar na comunicação dos microsserviços. 

Considerando que APIs são um tópico essencial na comunicação entre microsserviços, elas serão abordadas em maior profundidade na \autoref{boas-praticas-apis}.

\section{A metodologia de 12 fatores}

A metodologia de 12 fatores para o desenvolvimento de aplicativos é um conjunto de regras e diretrizes para o desenvolvimento de aplicativos nativos da nuvem e software como um serviço. De acordo com ela, os microsserviços devem respeitar as seguintes orientações: 

% Metodologia para construir saas que:
% Usam formatos declarativos para automatizar a configuração inicial, minimizar tempo e custo para novos desenvolvedores participarem do projeto;

% Tem um contrato claro com o sistema operacional que o suporta, oferecendo portabilidade máxima entre ambientes que o executem;

% São adequados para implantação em modernas plataformas em nuvem, evitando a necessidade por servidores e administração do sistema;

% Minimizam a divergência entre desenvolvimento e produção, permitindo a implantação contínua para máxima agilidade;

% E podem escalar sem significativas mudanças em ferramentas, arquiteturas, ou práticas de desenvolvimento.

% Este documento sintetiza toda nossa experiência e observação em uma variedade de aplicações que operam como software-como-serviço. Isto é a triangulação de práticas ideais ao desenvolvimento de software, com uma atenção particular a respeito das dinâmicas de crescimento orgânico de uma aplicação ao longo do tempo, a dinâmica de colaboração entre desenvolvedores trabalhando em uma base de código, e evitando os custos de erosão de software

% A metodologia doze-fatores pode ser aplicada a aplicações escritas em qualquer linguagem de programação, e que utilizem qualquer combinação de serviços de suportes (banco de dados, filas, cache de memória, etc).

% 12-Factor Application - É uma metodologia de desenvolvimento que diz que os logs devem ser um stream de dados. Esses logs podem ser impressos na saída padrão, e um serviço específico de logs coleta esses logs, faz o parse, categorização, relatório e todo processamento necessário - https://12factor.net/

I. Base de Código - Cada microsserviço deve ter uma base de código única e particular, com rastreamento utilizando controle de revisão, e devem ser criados várias implantações.

II. Dependências - Cada microsserviço deve declarar e isolar suas dependências.

III. Configurações - Configurações de ambiente devem ser armazenadas fora do microsserviço, para que ele possa decidir a configuração apropriada a ser usada.

IV. Serviços de Apoio - Os microsserviços não devem fazer distinção entre serviços de terceiros e serviços locais.

V. Construir, lançar, e executar - Deve-se separar e distinguir cada etapa do processo de desenvolvimento. Na etapa de construção, o código é transformado em um executável. Na etapa de lançamento, o executável se combina com a configuração atual da implantação, seja teste, desenvolvimento ou produção. Na etapa de execução, o aplicativo é executado no ambiente adequado ao lançamento selecionado.

VI. Processos - Deve-se executar a aplicação como um ou mais processos que não armazenam estado, assim diminuindo o acoplamento e facilitando o escalamento.

VII. Vínculo de porta - Um microsserviço deve ser executado em um container e exposto por meio de portas.

VIII. Concorrência - Cada processo deve ser independente e executado separadamente, para se ter um melhor dimensionamento e ser capaz de executar mais ao mesmo tempo.

IX. Descartabilidade - Deve ser possível iniciar ou interromper a aplicação imediatamente sempre que necessário. Caso a aplicação pare de funcionar, deve ser capaz de iniciar novamente sem perdas.

X. Paridade de desenvolvimento e produção - Deve-se manter os ambientes de desenvolvimento, teste e produção o mais semelhantes possível.

XI. Logs - Logs devem ser tratatos como um fluxo de eventos.

XII. Processos administrativos - Tarefas de administração ou de gerenciamento devem ser executadas como processos únicos. \cite{12factor, oracle_microservices}

\section{Monitoramento}

Em qualquer aplicação o monitoramento é importante para garantir um bom funcionamento. Entretanto, na arquitetura de microsserviços o monitoramento se torna indispensável, além de mais complexo. % Automação e monitoramento estão altamente ligados.

resource usage and load balancing as monitoring metrics, log management and exception tracking as monitoring practices are widely used \cite{design-monitoring-testing-waseem}

\subsection{Históricos}

Um histórico, também conhecido como \emph{log}, descreve o que aconteceu em determinado sistema e provê informações sobre o estado e a saúde dele. Manter um histórico do microsserviço é uma das formas mais simples de se implementar monitoramento, e é fortemente indicado. 

Para facilitar a escrita, leitura e operação dos históricos, deve-se padronizar o formato deles em todos os microsserviços e diferenciar entradas de erros, de avisos e de informação. Além disso, eles devem ser agregados e organizados em um único lugar para que possam ser facilmente consultados.

Pode haver um serviço dedicado para logs, ou um sidecar de logs (pacote instalável).

% Um motivo importante para organizar os logs é rastrear as chamadas de uma execução. Devemos poder reconstruir uma operação a partir de um identificador. Isso é o equivalente à stack-trace de um sistema monolítico.

% Usar ferramentas de gerenciamento (APMs - Application performance management) para visualizar essas stack-traces.

\subsection{Métricas}
Métricas nos permitem saber o que está acontecendo em qualquer momento, e decidir que ações devem ser tomadas a partir disso. Escalar um serviço que recebe muitas requisições por exemplo, ou diminuir um que não. Métricas podem inclusive servir para questões de negócios e de \emph{business inteligence}. 

Enquanto históricos precisam ser desenvolvidos, métricas apenas precisam de instrumentação pois muitas ferramentas já possuem as próprias métricas ou já existem métodos consolidados para as obter. Nos servidores web mais populares, por exemplo, as informações básicas sobre uma requisição já são gravadas por padrão.

É recomendado usar dashboards de alto nível para melhorar a visualização e monitoramento do status da aplicação a partir de suas métricas.

\section{Lidando com dados}

"A estabilidade do serviço está diretamente relacionada ao banco de dados que ele acessa."

        - Single service database
            ~ Problema: Escalabilidade do serviço e do banco são fortemente relacionados.
            ~ Solução: Cada serviço (quando necessário) terá seu próprio banco de dados.

        - Shared service database
            ~ Problema: Às vezes precisamos centralizar os dados (talvez por motivos contratuais, por exemplo, dois dados acessados por microserviços diferentes precisam estar disponível no mesmo banco de dados). Nesse caso o banco escala conforme a necessidade do maior desses microserviços.
            ~ Solução: Tratar esse banco em cada serviço como se ele fosse separado.

        Geralmente há preferência pelo **single service database**, não compartilhando bancos de dados entre serviços. Mas quando necessário, usa-se o **shared service database**, mas sempre tratando o banco de dados em cada serviço como se ele fosse separado.
        Com cada serviço tendo seu próprio banco, a escalabilidade do serviço e banco pode ser feita em conjunto. Assim, serviços que recebem poucos acessos podem ter bancos menos potentes e mais baratos, e vice-versa.

        - Um padrão de codificação: CQRS - Command Query Resposibility Segregation (Segregação da responsabilidade entre o comando e uma busca)
            "At its heart, [CQRS] is the notion that you can use a different model to update information than the model you use to read information. For some situations, this separation can be valuable, but beware that **for most systems, CQRS adds risky complexity**."

           Ou seja, usar um modelo para leitura (busca) e outro modelo diferente para escrita (inserção/edição). É possível ter um banco de dados de escrita e outro de leitura, e fazer uma sincronização entre esses. Essa ideia é muito facilitada usando-se o padrão CQRS.
           
           . Com leitura e escrita separados, cada parte pode realizar operações mais complexas
           . O modelo de leitura pode ter informações agregadas de outros domínios
           . O modelo de escrita pode ter dados sendo automaticamente gerados
           . Aumenta **muito** a complexidade de um sistema

        - Eventos assíncronos
            [Um tipo de arquitetura: Event sourcing - ter toda a base dos dados através de eventos. Para reconstruir os dados, há uma lista de eventos (Pesquisar mais)]
            . Determinados problemas não podem ser resolvidos na hora. (Um pagamento, por exemplo)
            . Um serviço emite um evento que será tratado em seu devido tempo
            . Usar tecnologias de mensageria e serviços de stream de dados - filas de mensageria: RabbitMQ. Serviço de streaming de dados: Kafka)

\section{APIs}\label{boas-praticas-apis}

Considerando que APIs são uma parte crucial no desenvolvimento de microserviços, sendo responsável por grande parte da comunicação que se faz necessária para conectar tantos serviços separados e manter um funcionamento eficiente e livre de falhas, esse trabalho terá um foco grande em boas práticas no desenvolvimento de APIs.

\subsection{Códigos de status de respostas HTTP}
Esses códigos são números entre 100 e 599, cada um tendo um significado diferente, e cada centena sendo classificada em tipos diferentes de resposta. 100-199 representam respostas de informação. 200-299 representam respostas de sucesso. 300-399 representam tipos de redirecionamentos. 400-499 representam erros por parte do cliente. 500-599 representam erros por parte do servidor. Isso é um padrão definido na seção 10 da RFC 2616 \cite{rfc_http_nielsen_1999}, e facilita com que o cliente entenda o que aconteceu com a requisição à API. Esses códigos devem ser enviados juntos com a resposta à requisição.

\subsection{Troca de dados com JSON}
Atualmente JSON é um dos formatos mais populares para troca de dados na web, pelo fato de ser facilmente lido tanto por humanos quanto por máquinas. Em APIs, JSON é usado para enviar e receber requisições por meio do protocolo HTTP, sendo uma solução robusta para a comunicação entre cliente e servidor. Embora seja derivado do JavaScript, JSON também é suportado por muitas outras linguagens, seja nativamente ou por meio de bibliotecas.  \cite{json_bourhis_2020}

% \subsection{Endpoints com aninhamento}
% Implementar \emph{endpoints} com aninhamento é uma boa prática pois expõe as relações entre diferentes \emph{endpoints}.

% If you are developing a REST API with categories, it is good to implement endpoint nesting as it shows the relationship between different endpoints. \cite{rapidAPI-twitter}

\subsection{Contratos de dados e versionamento}
Uma API depende de contratos de dados, isso é, uma definição dos dados que serão recebidos e retornados. Esse contrato implica num compromisso de manter o serviço correspondente funcionando e inalterado. Entretanto, é possível desenvolver melhorias ou adicionar funcionalidades sem quebrar o contrato. Para tanto, deve ser feito um versionamento da API e deve ser mantida a transparência com os clientes que a usam. Por exemplo, sempre que algo for alterado é preciso atualizar a documentação.

Para fazer o versionamento, pode-se usar o processo de versionamento de software para representar os estados da API. Nesta técnica, usa-se três números para representar a versão, por exemplo "2.3.7". O primeiro representa a versão maior, o segundo, a versão menor, e o terceiro, o patch (pequena atualização para consertar ou melhorar algo). \cite{wiki_software_versioning_2022}

Em uma API, para cumprir o contrato de dados, apenas modificações aditivas podem ser feitas, tais como novos endpoints ou novos campos opcionais em algum recurso. Quando isso é feito, a versão da API muda de 2.3.7 para 2.4.0 ou para 2.3.8 dependendo do tamanho da mudança.

Quando é necessário realizar alterações que descumprem o contrato, deve-se alterar a versão maior da API, por exemplo passando de 2.3.7 para 3.0.0. Nesses casos, é importante manter a versão anterior funcionando e inalterada, criando uma nova rota para acessar a versão nova, para que clientes usando a versão anterior não apresentem falhas.
% citar o curso da alura

\subsection{API Gateway}\label{boas-praticas-api-gateway}
Numa arquitetura de microsserviços, os clientes geralmente consomem funcionalidades de mais de um microsserviço. Se esse consumo é feito do cliente diretamente para o microsserviço, o cliente precisa lidar com várias requisições aos \emph{endpoints}. Quando os microsserviços mudam ou mais microsserviços surgem frequentemente, fica inviável tratar tantos endpoints por parte do cliente. Uma solução para isso é usar um \emph{API Gateway}. 

Um \emph{API Gateway} é um padrão de projeto e funciona como uma porta única de entrada para as APIs de cada microsserviço, padronizando e controlando o acesso aos microsserviços e APIs. Esse gateway fica situado entre o cliente e os microsserviços, e é responsável por redirecionar as requisições recebidas para os microsserviços apropriados, assim o gerenciamento das chamadas pode ser feita em apenas um lugar em vez de em cada API de cada microsserviço. Além disso, nele também podem ser implementadas camadas de segurança e de monitoramento.

Outra vantagem é que esse \emph{API Gateway} pode agregar requisições, permitindo que o cliente envie apenas uma requisição para o \emph{API Gateway} para recuperar informações de diferentes microsserviços, o que normalmente exigiria múltiplas requisições. Nesse caso, quando recebida a requisição do cliente, o \emph{API Gateway} fica responsável por disparar as requisições correspondentes, agregar as respostas e as devolver ao cliente.

Entretando, também há desvantagens no uso desse padrão: (1) há um acoplamento forte entre os microsserviços e o \emph{API Gateway}, (2) surge um possível ponto massivo de falha nesse \emph{API Gateway}, (3) Se não escalado adequadamente, esse \emph{API Gateway} pode se tornar um gargalo. \cite{microsoft-api-gateway}

\subsection{Segurança em APIs}

\subsubsection*{Autenticação}

Incluir autenticação em uma API consiste em exigir uma prova de autorização do uso da API. A autenticação nas APIs é indispensável para aumentar a segurança, e existem formas diferentes de implementá-la, as quais serão melhor discutidas no \autoref{chapter-solucoes}.

\subsubsection*{Validação de entradas}

Validar entradas significa verificar as requisições que chegam com o intuito de garantir que elas não contém dados impróprios, tais como injeções de SQL ou \emph{scripting} entre sites (scripting significa executar uma determinada sequência de comandos). Essa validação deve ser implementada tanto em nível sintático como em semântico, isso é, tanto impondo correção da sintaxe quanto impondo correção de valores. \cite{rapidAPI-twitter}

\subsubsection*{Certificado Secute Socket Layer (SSL)}
Usar um certificado SSL permite que o protocolo HTTPS seja usado em vez do HTTP, criptografando as informações que estão trafegando, o que adiciona uma camada de segurança. \cite{rapidAPI-twitter}

\subsubsection*{Limitação de taxa de requisições}
Limitar a taxa de requisições é um jeito de proteger a infraestrutura do servidor nos casos de acontecerem grandes fluxos de requisições, tal como em um ataque de \emph{DoS} (negação de serviço). Clientes terão seu acesso bloqueado caso enviem uma quantidade de requisições acima do limite determinado. \cite{rapidAPI-twitter}

\subsubsection*{Compartilhar o mínimo possível}
Compartilhar o mínimo possível é uma medida de segurança genérica que pode ser adotada em qualquer microsserviço. Especificamente nas APIs, deve-se retornar estritamente apenas os dados necessários para o cliente. Muitas ferramentas usadas para implementar APIs incluem por padrão informações como se fossem marcas d'água, mas que podem ser removidas, tal como headers "X-Powered-By", que vazam informações do servidor que podem auxiliar usuários mal-intencionados. \cite{rapidAPI-twitter}

\subsection{Testar a API}
Testar uma API isoladamente serve para determinar se ela atende a parâmetros pré-definidos ou não. Tais parâmetros podem ser o cumprimento da funcionalidade, a confiabilidade, a latência, o desempenho, e a segurança. Quando um teste de API falha, deverá ser possível saber precisamente onde o problema se encontra, assim aumentando a velocidade de desenvolvimento e a qualidade do produto. As ferramentas que podem ser utilizadas para testes em APIs são discutidas na sessão \autoref{ferramentas-testes-apis}.

% Why should you perform API testing?
% - Testing your APIs timely helps to ensure your app is up all the time.
% - It helps to detect API security and performance issues.
% Benefits of API Testing
% - When API tests fail, you will know precisely where the issue lies that crashed the system.
% - As data is exchanged via XML or JSON, you can write API tests in your preferred language.
% - API testing also helps to release the next API version faster. \cite{rapidAPI-twitter}

\subsection{Salvar a resposta no \emph{cache}}
Às vezes referido como \emph{cachear}, salvar informações no \emph{cache} melhora o tempo de busca da informação. Em uma API podem haver múltiplas requisições para a mesma informação em um curto intervalo de tempo, e para cada requisição será necessário buscar a informação. Entretanto, se a informação estiver salva no \emph{cache}, não será necessário buscar essa informação, o que melhora o tempo de resposta da API, especialmente em \emph{endpoints} que frequentemente retornam a mesma resposta. \cite{rapidAPI-twitter}

\subsection{Comprimir os dados}
A transferência de cargas grandes pode diminuir a velocidade da API. Comprimir os dados auxilia nesse problema, diminuindo o tamanho da carga e aumentando a velocidade de transferência. \cite{rapidAPI-twitter}

% There are various compression methods available, a common one being GZIP. \cite{rapidAPI-twitter}

% \subsection{Evitar trazer ou buscar resultados a mais ou a menos}
% Over-fetching results in unnecessary and unusable data, and under-fetching results in an incomplete response. Good architecture, planning, and appropriate API management tools are essential to avoid these. \cite{rapidAPI-twitter}

\subsection{Paginar e filtrar}
A Paginação separa e categoriza resultados, enquanto a filtragem retorna apenas os resultados relevantes de acordo com os parâmetros da requisição. A paginação e filtragem de resultados reduz a complexidade da resposta e facilitam o uso da API. \cite{rapidAPI-twitter}

\subsection{PATCH ou PUT}
Quando é necessário modificar um recurso em uma API, usa-se os métodos HTTP PUT ou PATCH. Enquanto PUT atualiza o recurso inteiro, PATCH atualiza apenas uma parte específica do recurso, assim usando uma carga de dados menor. Portanto, quando possível deve-se usar PATCH em vez de PUT para modificar um recurso. \cite{rapidAPI-twitter}

\section{Testes}

O processo de testes para microsserviços engloba várias estratégias diferentes de testes. Essas estratégias podem ser incluir testes funcionais, como um teste de unidade, ou testes não-funcionais, como um teste de desempenho. Usar múltiplas estratégias de testes garante que a aplicação opera com sucesso em ambientes e plataformas diferentes. 

% We identified 12 testing strategies (see Table 28), which are listed in our survey question, from the literature (e.g., [9, 6, 61, 63, 64, 65, 66, 67]).

De acordo com \citeonline{design-monitoring-testing-waseem}, testes de unidade e testes fim-a-fim são as estratégias de testes mais usadas. Mas de acordo com \cite{Familiar2015}, deve-se também testar os microsserviços conforme passam pelo \emph{pipeline} de implantação. Isso inclui:

- Testes internos: Testar as funções internas do serviço, inclusive uso de acesso de dados, e caching.

- Teste de serviço: Testar a a implementação de serviço da API. Essa é uma implementação privada da API e seus modelos associados.

- Teste de protocolo: Testar o serviço no nível de protocolo, chamando a API sobre o determinado protocolo (geralmente HTTP).

- Teste de composição: Testar o serviço em cooperação com outros serviços no contexto de uma solução.

- Teste de escalabilidade/taxa de transferência: Testar a escalabilidade e elasticidade do microsserviço implantado.

- Teste de tolerância a falha: Testar a capacidade do microsserviço de recupera-se após uma falha.

- Teste de penetração: Trabalhar com uma empresa terceirizada de segurança de software para realizar testes de penetração no sistema. \cite{Familiar2015}

% \section{Agregando serviços (process agregator pattern)}
% Um padrão popular Agregar serviços de negócio em um único serviço mantém as funções em um nível mais alto. 

% Agrega serviços de negócio (É ainda mais alto nível)

% Fazem as chamadas para os serviços necessários e montam uma resposta adequada

% Deve ter uma lógica de processamento, e não ser apenas um proxy. No mínimo deve unir a resposta de diversos serviços

% Para construir um agregador, define-se um novo modelo para o sistema, que representará os dados agregados como um subnegócio

% A partir deste modelo, pensar na API que fornecerá as operações

% A ideia é relativamente simples, mas a implementação pode ser complexa

% \section{Pontos de entrada para cada tipo de cliente} 
% Gateway específico para determinados clientes

% Foco nas necessidades reais de determinados clientes

% Esses clientes podem ser clientes da API, como clientes HTTP, ou clientes de negócio mesmo

% Por exemplo, em vez de modificar a lógica de negócios, cria-se um novo 'edge', que receberá a resposta e modificará de acordo com a necessidade do cliente

% Uma possibilidade seria trabalhar apenas com edge services, e nenhum API gateway, isso é, não existiria um ponto único de entrada universal, mas sim um para cada tipo de cliente

% Para construir uma edge (ponta), deve-se primeiro Identificar o cliente e suas necessidades, e Construir contratos específicos para o cliente, isso é, ter recursos diferentes para cada cliente. Por exemplo, a URL pode ser diferente de cliente web para clientes mobile.

% \section{Do monólito aos microserviços}

% Separando serviços monolíticos

% - Separando serviços de domínio (Data Service):
%     . Usar Domain-Driven Design (DDD)
%     . Começar modelando o domínio, não pensando na persistância. Definir previamente as regras e o domínio (Programação orientada a interfaces), para então...
%     . Avaliar **quais ações serão disponibilizadas neste serviço**. (Ex: Inserir, editar, recuperar, exibir, etc...)
%     . Construir o serviço, pensando primeiro no contrato
%     . REST e RPC podem andar juntos

% - Separando serviços de negócio (Business Service):
%     . Identificar o processo que deve ser exposto
%     . Identificar os domínios que serão necessários nesse serviço
%     . Defina a API que será utilizada, focando no domínio e não nos dados. (Ex: Passar uma matrícula, e não um ID)
%     . Consumir serviços de domínio para executar os processos

% - Padrões
%     . Strangler pattern
%         ~ Quebrar um monolito, tirando as funcionalidades dele aos poucos
%         ~ Pode-se começar isolando os dados
%         ~ Ou pode-se começar isolando o domínio

%     . Sidecar pattern
%         ~ Compartilhar código sem que seja necessário criar um novo microserviço.
%         ~ Usa-se pacotes a parte, que podem ser facilmente instalados.
%         ~ Esses pacotes só precisam ser alterados em um lugar para ter efeito em todos os microserviços.
%         ~ Ex: pacotes do npm, do composer, do maven, etc

% \subsection{Identificação com DDD}\label{praticas-identificacao-com-ddd}

% a combination of domain-driven design and business capability is the most used strategy to decompose an application into microservices \cite{design-monitoring-testing-waseem}

% Um caminho possível para facilitar a identificação com DDD dos microsserviços seria em vez de projetar os modelos e os contextos limitados (conceito do DDD usado para limitar um domínio, dividindo modelos grandes e explicitando as relações entre eles) separando-os em camadas, deve-se juntar os contextos limitados com seus respectivos modelos, e procurar por possíveis pontos de separação da aplicação - um lugar onde a linguagem muda, por exemplo. Isso resultaria em um ponto de partida para separar as partes e formar uma arquitetura de microsserviços. \cite{Familiar2015}

% If you are currently working with a complex layered architecture and have a reasonable domain model defined, the domain model will provide a roadmap to an evolutionary approach to migrating to a microservice architecture. If a domain model does not exist, you can apply domain-driven design in reverse to identify the bounded contexts, the capabilities within the system. \cite{Familiar2015}

% % Domain-driven design (design orientado a domínio) é uma tecnica bem consolidada e muito usada no desenvolvimento de software. Entretanto, para aplica-la em microsserviços, é necessário analisar onde cada peça desse padrão de projeto deve ficar. Em vez de projetar os modelos e os contextos limitados separando-os em camadas, pode-se juntar os contextos com seus respectivos modelos, e procurar por possíveis pontos de separação da aplicação - um lugar onde a linguagem muda, por exemplo. Isso resultaria em um ponto de partida para separar as partes e formar uma arquitetura de microsserviços. \cite{Familiar2015}

% \subsection{Organização}

% Em uma mudança do monólito para microsserviços, é recomendado que não sejam feitas mudanças grandes e abruptas na sua organização. Em vez disso, deve-se procurar uma oportunidade com uma iniciativa de negócio para testar a fórmula proposta por \citeonline{Familiar2015} : 

% - Formar um pequeno time inderdisciplinar (cross-functional?).

% - Oferecer treinamento e orientação na adoção de práticas ágeis, como o scrum.

% - Oferecer uma localização física separada para esse time trabalhar a fim de não afetá-lo negativamente por politicas internas ou hábitos antigos.

% - Adotar uma abordagem de minimo produto viável para entregar pequenos mas incrementais \emph{releases} de software, usando essa abordagem durante todo o ciclo de vida.

% - Integrar esse serviço com sistemas existentes, usando um acoplamento solto.

% - Percorrer esse ciclo de vida do microsserviço diversas vezes, fazendo as adaptações necessárias até chegar a equipe ficar confortável com o processo.

% - Colocar o time principal em posições de liderança enquanto são formados novos times interdisciplinares para disseminar o conhecimento e a prática.