\chapter{Desenvolvimento da aplicação}\label{chapter-ferramentas}
%https://dzone.com/articles/30top-tools-for-building-microservices-on-all-leve
\chapterprecis{Este capítulo aprensenta ferramentas que podem ser usadas no desenvolvimento de aplicações com arquitetura de microsserviços}\index{sinopse de capítulo}

% \section{Design, testes, e monitoramento}

% De acordo com \citeonline{design-monitoring-testing-waseem}, mais pesquisas são necessárias para lidar com a complexidade dos microsserviços no nível de \emph{design} (projeto), de monitoramento, e de testes, desafios para qual não há soluções dedicadas.

Quando se está procurando por ferramentas para o desenvolvimento de aplicações, a quantidade imensa de opções disponíveis pode ser opressiva. Perguntas como "Para que serve a ferramenta X"? "Qual a diferença entre a ferramenta X e a ferramenta Y", "Em qual cenário eu devo usar a ferramenta X?", "Qual ferramenta funciona melhor com a ferramenta X?" são muito comuns para iniciantes ou mesmo para pessoas experientes, mas em poucas ferramentas. E apesar de nem sempre existirem respostas concretas para essas perguntas ou das respostas mudarem com o passar do tempo, esse capítulo provê uma orientação superficial para o desenvolvedor que procure entender o contexto de cada ferramenta e o que elas têm a oferecer.

Ferramentas de código aberto ou com opções gratuitas estão seguidas de um asterisco (*).
Expor uma boa quantidade de ferramentas tal que supra as necessidades mais frequentes de uma arquitetura de microsserviços, com espaço para alternativas.

>>> Manter em mente: Focar em soluções de infraestrutura, pois As soluções para os requisitos/problemas de **negócio** podem ser iguais tanto na arquitetura monolítica quanto na de microsserviços, ou >seja, podem ser satisfeitos/solucionados nas duas arquiteturas.

\section{Resource Management Problems}
This category provides the mapping of problems and solutions for different types of resources required to implement MSA in DevOps. Study (S01) recommends the virtualization of applications, infrastructures, and platforms resources as a solution for addressing resource management problems. Study (S09) suggests using containers and VMs for microservices in DevOps to get the desired level of efficiency in resource utilization. Study (S03) proposes the HARNESS approach (i.e., a DevOps based approach) that provides a cloud-based platform for bringing together commodity and specialized resources (e.g., skilled people). Study (S19) introduces an MSA based SONATA NFV platform with DevOps to address resource management problems by providing a set of tools (e.g., GitHub, Jenkins, Docker). The SONATA NFV platform can also create the CI/CD pipeline to automate steps in software delivery process. Study (S09) argued that dedicated access to the host’s hardware can be increased either by giving extra privileges to microservices or by enhancing the capability of containers to access the host resources.

asdfasdf. \cite{Tanembaum-Steen}.

\citeonline{Tanembaum-Steen} afirma que...


\section{Linguagens de programação}
Java, JavaScript, Python, Elixir. \footnote{Uma linguagem de programação não pode, por sí só, ser caracterizada como código aberto ou não, mas uma implementação de uma linguagem pode. Para o escopo deste trabalho, todas as implementações mais comuns das linguages de programação citadas são válidas.}

% A programming language isn't in it self open source or not, but an implementation of it might be. Yes, there are open source implementations of Java. Sun's Java implementation (the most popular one), is one of them.

\section{Frameworks}
TODO: Para microsserviços, ...

\section{Servidor Web}
TODO: nginx, apache. 
Importante distinguir servidores web de servidores de aplicação...

\section{Bancos de dados}
TODO:

\subsection{Tipos de bancos de dados}


\subsection{Escalamento}

\subsubsection{CQRS}
\emph{Command Query Responsibility Segregation (CQRS)} - Segregação de Responsabilidade de Consulta de Comando. 

Trata-se de usar um modelo para escrita e outro para leitura. Adicionar complexidade. 

"CQRS stands for Command Query Responsibility Segregation, which is a software design pattern that separates the operations for reading data (queries) from those for writing data (commands). This separation allows each operation to be optimized independently, improving performance and scalability in complex applications."


- ler: https://martinfowler.com/bliki/CQRS.html


\subsubsection{Replicação}
- ler: https://atlan.com/what-is/database-replication/

- ler: https://release.com/blog/syncing-databases-how-to-do-it-and-best-practices

- Aplicação: https://stackoverflow.com/questions/58399450/keeping-databases-in-sync-after-write-update-across-regions-zones

- ver se tem algum serviço assim na AWS

\subsection{Relacionais}
MySQL*, PostgreSQL*, MariaDB*

\subsection{Not-only SQL}
MongoDB*, Couchbase*, Redis*, Amazon DynamoDB

\subsection{Caching}
Memcached (*), Redis

\section{Integração contínua e Entrega Contínua (CI/CD)}

GitHub Actions ou GitLab... 

re-ler: https://martinfowler.com/bliki/ContinuousDelivery.html

Gitlab: \url{https://about.gitlab.com/topics/ci-cd/} e \url{https://docs.gitlab.com/ci/} e \url{https://gitlab.com/microsservicos1/TesteGitLab/-/learn_gitlab}

- Reler: https://martinfowler.com/articles/continuousIntegration.html

Automatizar testes e builds para cada commit em qualquer branch permite feedback rápido, garantindo que o código esteja em um estado consistente em todas as branches, promovendo uma prática de CI eficiente. (Fonte: curso do vinicius)

Many software tools are available to support implementing CI/CD practices. These CI/CD tools range from repository management such as Github and Bitbucket, Jenkins for build automation, and Selenium and Katalon Studio for test automation.

What are some common CI/CD tools?
CI/CD tools can help a team automate their development, deployment, and testing. Some tools specifically handle the integration (CI) side, some manage development and deployment (CD), while others specialize in continuous testing or related functions.
One of the best known open source tools for CI/CD is the automation server Jenkins. Jenkins is designed to handle anything from a simple CI server to a complete CD hub.
Deploying Jenkins on Red Hat OpenShift

Tekton Pipelines is a CI/CD framework for Kubernetes platforms that provides a standard cloud-native CI/CD experience with containers.
Deploying Jenkins on Red Hat OpenShift

Beyond Jenkins and Tekton Pipelines, other open source CI/CD tools you may wish to investigate include:
    Spinnaker, a CD platform built for multicloud environments.
    GoCD, a CI/CD server with an emphasis on modeling and visualization.
    Concourse, "an open-source continuous thing-doer."
    Screwdriver, a build platform designed for CD.

Teams may also want to consider managed CI/CD tools, which are available from a variety of vendors. The major public cloud providers all offer CI/CD solutions, along with GitLab, CircleCI, Travis CI, Atlassian Bamboo, and many others.
Additionally, any tool that’s foundational to DevOps is likely to be part of a CI/CD process. Tools for configuration automation (such as Ansible, Chef, and Puppet), container runtimes (such as Docker, rkt, and cri-o), and container orchestration (Kubernetes) aren’t strictly CI/CD tools, but they’ll show up in many CI/CD workflows. \cite{redhat-ci-cd}

\subsection{Sistema de controle de versão}
% Usar um sistema de controle de versão é a estritamente necessário para se ter integração contínua. 
Existem sistemas de controle de versão distribuidos (DVCS) ou centralizados (CVCS), porém atualmente os distribuitos são o padrão no desenvolvimento de \emph{software}, e pouco se ouve falar dos centralizados. O \textbf{Git} é de longe o mais famoso entre todos os sistemas de controle de versão, e é uma solução elegante e completa para o controle de versão no desenvolvimento de \emph{software}.

\subsection{Gerenciamento de repositórios}
GitHub, Bitbucket, GitLab, amazon S3

\subsection{Automação de testes}
Selenium para navegadores

\subsection{Servidor de integração}
Como mencionado na \autoref{subsecao-servidor-de-integracao}... Normalmente a responsabilidade de executar a pipeline de integração é delegada para um servidor de integração, em vez de confiar no desenvolvedor para executá-la manual e localmente sempre antes de fazer algum commit. Assim tem-se a garantia de que a pipeline será de fato executada e o desenvolvedor não precisa ficar aguardando ela ser executada na máquina dele.

Mostrar o exemplo do pipeline CI rodando no GitHub Actions, com proteções de branch e requerimento de revisão de código

\url{https://about.gitlab.com/topics/ci-cd/continuous-integration-server/}

\url{https://www.ibm.com/docs/en/integration-bus/10.1?topic=environment-integration-servers}

\url{https://www.ibm.com/docs/en/app-connect/11.0.0?topic=overview-integration-servers-integration-nodes}

CruiseControl*, Jenkins, GitHub Actions, GitLab CI, etc
% Listamos abaixo alguns servidores de integração disponíveis no mercado. Isso não é uma lista ordenada por popularidade e algum outro critério. Alguns servidores são opensource, outros não, alguns são pagos ou podem ser alocados na nuvem e outros só existem para nuvem ou instalação local.

% Em geral, não existe uma bala de prata e a melhor ferramenta é aquela que te serve bem:
%     Jenkins (https://jenkins.io/)
%     GoCD (https://www.gocd.org/)
%     Bamboo (https://www.atlassian.com/br/software/bamboo)
%     Travis CI (https://travis-ci.org/)
%     Team City (https://www.jetbrains.com/teamcity/)
%     Circle CI (https://circleci.com/)
%     Gitlab (https://about.gitlab.com/product/continuous-integration/)
%     AWS Code Pipeline https://aws.amazon.com/codepipeline/
%     Azure (https://azure.microsoft.com/pt-br/services/devops/server/)

% At Thoughtworks, we're big fans of continuous integration servers - indeed we led the original development of CruiseControl and CruiseControl.NET, the widely used open-source CI servers. Since then we've also built the commercial Cruise CI server. We use a CI server on nearly every project we do and have been very happy with the results.
\section{Testes}
Existem diversos tipos de teste, Teste Manual vs Automatizado vs Contínuo. Mas não é o foco do trabalho

\subsection{Testes Manuais}
\subsection{Testes unitários}
\subsection{Testes de integração}

\subsection{Testes de API}\label{ferramentas-testes-apis}
Postman*, Hoppscotch*, Thunder Client (VSCode)
programar os testes em uma linguagem de programação
cURL
postman
solução integrada ao VSCode - thunderclient, rapidAPI


\section{Comunicação}

\subsection{RPC}
gRPC (\url{https://grpc.io/})

\subsection{Mensageria}
RabbitMQ*, Azure Service Bus, Amazon Simple Queue Service, Google Cloud Pub/Sub.

\subsection{Streaming de Dados}
Apache Kafka*

\subsection{APIs}

\subsubsection{API Gateway}
nginx (free and paid version), Tyk*, Amazon API Gateway

\subsubsection{Tipos de API}

\subsubsubsection{GraphQL}
GraphQL 

\subsubsubsection{REST}
REST is not a protocol or a standard, it is an architectural style. During the development phase, API developers can implement REST in a variety of ways.

Like the other architectural styles, REST also has its guiding principles and constraints. These principles must be satisfied if a service interface has to be referred to as RESTful.

A Web API (or Web Service) conforming to the REST architectural style is called a REST API (or RESTful API). 

6 princípios: https://www.ibm.com/think/topics/graphql-vs-rest-api

\subsubsection{Documentação}
Swagger (free and paid version)

% \subsection*{GraphQL}
% A query language for your API
% GraphQL is a query language for APIs and a runtime for fulfilling those queries with your existing data. GraphQL provides a complete and understandable description of the data in your API, gives clients the power to ask for exactly what they need and nothing more, makes it easier to evolve APIs over time, and enables powerful developer tools. \cite{GraphQL-site}

\section{Provisionamento}

\subsection{de máquinas virtuais}
VirtualBox*

\subsection{de containers}
Docker*, LXC (Linux containers)

\subsection{na nuvem}
AWS EC2

\subsection{automático}
AWS Launch Templates

% \section{Escalamento}
% AWS Auto Scaling Groups

% \subsection{Ferramentas para segurança em APIs}

% Autenticação - Always use secure authentication methods such as OAuth, JWTs, or API Keys. It's not recommended to use basic HTTP authentication as it sends user credentials with each request. It is considered the least secure method.

% Validação de entradas - Métodos de validação de entrada: JSON and XML Schema validation; Regular expressions;  Data type validators available in framework; Minimum and maximum value range check for numerical inputs;  Minimum and maximum length check for strings.

% \subsubsection{Métodos de autenticação}

% API Keys are unique identifiers assigned to clients, which grant them access to an API. They are passed to the server with every request and authenticate the client. They also provide authorization and can be used to identify a user's individual access permissions. API Keys are long alphanumerical strings designed to be almost impossible to guess. They are passed to servers as a query parameter or in an HTTP request header.

% OAuth is a powerful framework that uses tokens to give apps limited access to a user’s data without needing the user’s password. The tokens used are restricted and only allow access to data that the user specified for the particular app. It works by the user(client) first requesting authorization from the resource owner. The user is then given a unique access token from an authorization server used in each request to the resource server.

% Basic HTTP authentication involves the client passing the user’s username and password with every request. This is done using an HTTP Header. Basic HTTP authentication is generally considered the least secure. However, if you decide to use it, ensure you are using an HTTPS connection. If not, data is a risk of being leaked.

% Ferramenta para rate limiting. \cite{rapidAPI-twitter}

\section{Orquestração de Containers}

Docker Swarm*, Kubernetes*, Conductor*, AWS EKS, Azure Kubernetes Service (AKS)

\subsection{Kubernetes}

% Learn About Orchestrating Microservices Using Kubernetes

% The microservices that are running in containers must be able to interact and integrate to provide the required application functionalities. This integration can be achieved through container orchestration.

% Container orchestration enables you to start, stop, and group containers in clusters. It also enables high availability and scaling. Kubernetes is one of the container orchestration platforms that you can use to manage containers.

% After you containerize your microservices, you can deploy them to Oracle Cloud Infrastructure Container Engine for Kubernetes.

% Before you deploy your containerized microservices application to the cloud, you must deploy and test it in a local Kubernetes engine, as follows:

%     Create your microservices application.
%     Build Docker images, to containerize your microservices.
%     Run your microservices in your local Docker engine.
%     Push your container images to a container registry.
%     Deploy and run your microservices in a local Kubernetes engine, such as Minikube.

% After testing the application in a local Kubernetes engine, deploy it to Oracle Cloud Infrastructure Container Engine for Kubernetes as follows:

%     Create a cluster.
%     Download the kubeconfig file.
%     Install kubectl tool on a local device.
%     Prepare the deployment.yaml file.
%     Deploy the microservice to the cluster.
%     Test the microservice.

% The following diagram shows the process for deploying a containerized microservices application to Oracle Cloud Infrastructure Container Engine for Kubernetes. \cite{oracle_microservices}

\section{Observabilidade e Monitoramento}

Modern tracing tools, such as Jaeger, Zipkin, and OpenTelemetry, help organizations implement distributed tracing efficiently. These tools collect, process, and visualize traces, often integrating with dashboards and monitoring platforms like Grafana or Prometheus for deeper insights. OpenTelemetry, in particular, is gaining traction as a vendor-neutral, open-source standard that unifies telemetry data across logs, metrics, and traces, making it easier to achieve full observability. As distributed systems continue to grow in complexity, tracing has become an essential practice for ensuring system reliability, minimizing downtime, and optimizing application performance.

\subsection{Métricas: Prometheus e Grafana}
Prometheus is an open-source monitoring and alerting tool designed for collecting and analyzing time-series data (metrics). It is widely used for monitoring infrastructure, applications, and services, especially in cloud-native and Kubernetes environments. \cite{prometheus-docs}

\subsection{Logging: Grafana Loki}
Grafana Loki, ou apenas Loki, é uma \emph{stack} para agregação e indexação de \emph{logs}, sendo composto por um conjunto de componentes independentes. Ele funciona recebendo um fluxo de \emph{logs} a partir de um agente que os captura da aplicação, e em seguida faz a indexação apenas de metadados deles, como um \emph{label} (rótulo), que apontam para os dados do \emph{log}, que são compactados e armazenados como objeto, assim consumindo pouco armazenamento. Além de consumir pouco armazenamento, o Loki também faz uso eficiente de memória; tem possibilidade para multilocação, ou seja, consegue escutar múltiplas aplicações enviando logs ao mesmo tempo, o que é importante em sistemas distribuidos; é altamente escalável, permitindo diferentes configurações de implantação; e permite que diversas outras ferramentas de observabilidade se conectem com ele. Entretanto, ele usa a própria linguagem de consulta - \emph{LogQL}, o que dificulta o aprendizado da ferramenta. Além disso, por indexar apenas metadados, a busca de \emph{logs} por conteúdo é mais dificil, e é preciso que os \emph{logs} sejam bem estruturados e rotulados para ser eficiente. \cite{grafana-loki}

\subsection{Logging: Graylog}
Graylog é um sistema de gerenciamento de \emph{logs} mais simples do que o Loki.
% Pode haver um serviço dedicado para logs, ou um sidecar de logs (pacote instalável).

Para manter registros, pode-se desenvolver um serviço dedicado a isso ou utilizar bibliotecas, para poder ser reutilizado onde necessário.

Logstash*, Sentry, Middleware, Elastic Stack, Graylog*

\section{Conjunto de ferramentas}
Seneca*, Google Cloud Functions,

\section{Framework arquitetural}
goa*, Kong*

\section{Aplicações \emph{serverless} (sem servidor)}
Claudia, Apache Openwhisk, Serverless, Kubeless, IronFunctions, AWS Lambda, OpenFaaS, Microsoft Azure Functions.

% \section{Plataformas}
% Microsoft Azure is a microservice platform, and it provides a fully automated dynamic infrastructure, SDKs, and runtime containers along with a large portfolio of existing microservices that you can leverage, such as DocumentDb, Redis In-Memory Cache, and Service Bus, to build your own microservices catalog. \cite{Familiar2015}
% AWS
% Uma solução para a sobrecarga na execução de tantos microserviços é a um ambiente de desenvolvimento integrado na linguagem CAOPLE \cite{CAOPLE}. Essa plataforma oferece grande controle sobre a implantação e testagem de microserviços.