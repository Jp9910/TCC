\chapter{Ferramentas para desenvolvimento de microsserviços}\label{chapter-ferramentas}
%https://dzone.com/articles/30top-tools-for-building-microservices-on-all-leve
\chapterprecis{Este capítulo aprensenta ferramentas frequentemente usadas e que cumprem propósitos importantes no desenvolvimento de aplicações com arquitetura de microsserviços.}\index{sinopse de capítulo}

% Ferramentas de código aberto ou com opções gratuitas estão seguidas de um asterisco (*).

% \section{Design, testes, e monitoramento}

% De acordo com \citeonline{design-monitoring-testing-waseem}, mais pesquisas são necessárias para lidar com a complexidade dos microsserviços no nível de \emph{design} (projeto), de monitoramento, e de testes, desafios para qual não há soluções dedicadas.

Quando se está procurando por ferramentas para o desenvolvimento de aplicações, a quantidade imensa de opções disponíveis pode ser opressiva. Perguntas como "Para que serve a ferramenta X"? "Qual a diferença entre a ferramenta X e a ferramenta Y", "Em qual cenário eu devo usar a ferramenta X?", "Qual ferramenta funciona melhor com a ferramenta X?" são muito comuns para iniciantes ou para pessoas experientes em poucas ferramentas. E apesar de nem sempre existirem respostas concretas para essas perguntas ou das respostas mudarem com o passar do tempo, esse capítulo provê uma orientação superficial para o desenvolvedor que procure entender o contexto de cada ferramenta e o que elas têm a oferecer.


% >>> Manter em mente: Focar em soluções de infraestrutura, pois As soluções para os requisitos/problemas de **negócio** podem ser iguais tanto na arquitetura monolítica quanto na de microsserviços, ou >seja, podem ser satisfeitos/solucionados nas duas arquiteturas.

% \section{Resource Management Problems}
% This category provides the mapping of problems and solutions for different types of resources required to implement MSA in DevOps. Study (S01) recommends the virtualization of applications, infrastructures, and platforms resources as a solution for addressing resource management problems. Study (S09) suggests using containers and VMs for microservices in DevOps to get the desired level of efficiency in resource utilization. Study (S03) proposes the HARNESS approach (i.e., a DevOps based approach) that provides a cloud-based platform for bringing together commodity and specialized resources (e.g., skilled people). Study (S19) introduces an MSA based SONATA NFV platform with DevOps to address resource management problems by providing a set of tools (e.g., GitHub, Jenkins, Docker). The SONATA NFV platform can also create the CI/CD pipeline to automate steps in software delivery process. Study (S09) argued that dedicated access to the host’s hardware can be increased either by giving extra privileges to microservices or by enhancing the capability of containers to access the host resources.

% asdfasdf. \cite{Tanembaum-Steen}.

\section{Serviços em nuvem}
% \section{Provedores em nuvem}
% \section{Infraestruturas, plataformas e serviços em nuvem}

% software as a SERVICE
% platform as a SERVICE
O uso de serviços em nuvem no desenvolvimento e lançamento de aplicações tem crescido cada vez mais na última década. As principais plataformas de nuvem, AWS, Azure e GCP, oferecem uma enorme variedade de serviços que permitem que aplicações sejam criadas, lançadas e mantidas com mais qualidade e de maneira mais simples. De interesse especial às aplicações com arquitetura de microsserviços, eles incluem serviços confiáveis e escaláveis de IaaS ou PaaS, oferencendo desde máquinas virtuais e contêineres até bancos de dados, sistemas de mensagens e soluções \emph{serverless}. Ao usar esses serviços, uma grande parte do trabalho de configuração e gerenciamento da infraestrutura ou plataforma é terceirizada para esses provedores, que quase certamente são melhores em lidar com essas questões. Além disso, a disponibilidade global dos centros de dados dos provedores de nuvem permite que aplicações sejam distribuídas geograficamente, reduzindo a latência e melhorando a experiência do usuário final. \cite{livro-building-microservices}

% Os provedores de nuvem também oferecem recursos avançados de segurança e conformidade, garantindo a proteção de dados e o cumprimento de normas regulatórias. Soluções como gerenciamento de identidade e acesso, criptografia de dados e monitoramento contínuo ajudam a proteger aplicações contra ameaças e falhas. 
% Outro fator importante que favorece o uso de serviços em nuvem é a segurança e conformidade oferecida pelos provedores, que geralmente implementam mecanismos avançados de proteção, como criptografia de dados, gerenciamento de identidade e acesso, além de auditorias e monitoramento contínuo. Isso possibilita que empresas atendam a regulamentações e padrões de segurança sem a necessidade de gerenciar a infraestrutura internamente. Dessa forma, o uso de serviços em nuvem não só otimiza o desenvolvimento e a implantação de aplicações, mas também garante maior confiabilidade, disponibilidade e inovação no ambiente digital.


% \subsection{Aplicações \emph{serverless} (sem servidor)}
% TODO: Poderia ter uma seção dedicada a falar sobre provedores em núvem e seus papeis no desenvolvimento/implantação de uma arquitetura de microsserviços. 

%    O livro \cite{livro-building-microservices} Capitulo 1 > Enabling technology > Public cloud and serverless tem informações interessantes sobre serverless 

% Soluções Serverless:  Claudia (expressJS), Apache Openwhisk, Serverless, Kubeless, IronFunctions, AWS Lambda, OpenFaaS, Microsoft Azure Functions.

\section{\emph{Frameworks} e linguagens de programação}

\emph{Frameworks} desempenham um papel fundamental no desenvolvimento de microsserviços, permitindo que os desenvolvedores criem sistemas modulares, escaláveis e de fácil manutenção de forma mais simples e evitando grande parte do código \emph{boilerplate}. A escolha do \emph{framework} e da linguagem pode dependender de diversos fatores, como os requisitos do sistema, a experiência da equipe e as preferências tecnológicas. Existem diversas opções disponíveis no mercado, cada uma com suas características, vantagens e desvantagens, sendo impossível abordar todas em detalhes. Dessa forma, aqui são discutidas apenas algumas das mais populares para o desenvolvimento de microsserviços.

\subsection{Java e Spring Boot}
Java é uma linguagem amplamente utilizada no desenvolvimento de microsserviços devido à sua robustez, escalabilidade e vasta gama de bibliotecas e ferramentas disponíveis. Spring Boot é um dos \emph{frameworks} mais populares para construir microsserviços em Java por simplificar o desenvolvimento de aplicações autônomas e de alto desempenho, permitindo que os desenvolvedores criem rapidamente serviços que podem ser facilmente integrados com outros sistemas. O Spring Boot oferece funcionalidades como configuração automática, injeção de dependência e integração com outros módulos do Spring, como o Spring Cloud, que facilita a implementação de microsserviços com capacidades de descoberta, balanceamento de carga e segurança. 
\cite{springboot}

A combinação de Java com Spring Boot é especialmente útil para empresas que já possuem uma base de código em Java ou que precisam de um ecossistema maduro com suporte a múltiplas ferramentas de monitoramento, escalabilidade e segurança. Além disso, a linguagem é fortemente tipada, o que ajuda a reduzir erros e a melhorar a manutenibilidade em sistemas grandes e complexos.

\subsection{Python e Flask ou Django}

Python é uma linguagem conhecida por sua simplicidade e rapidez de desenvolvimento, o que a torna uma escolha popular para prototipagem e desenvolvimento de microsserviços, especialmente quando o tempo é um fator crítico. Para a construção de microsserviços, \emph{frameworks} como Flask e Django são frequentemente usados. O Flask é um \emph{framework} minimalista e flexível, ideal para a criação de APIs simples e escaláveis. Ele fornece apenas os recursos essenciais, permitindo que os desenvolvedores escolham bibliotecas adicionais conforme necessário, o que dá flexibilidade para criar soluções sob medida. 
\cite{flask}

Por outro lado, Django é um \emph{framework} mais completo e robusto, adequado para aplicações maiores que exigem uma estrutura mais rígida. Embora o Django seja tradicionalmente mais utilizado para aplicações monolíticas, ele pode ser adaptado para um estilo de arquitetura de microsserviços. Ele vem com uma série de funcionalidades, como mapeamento objeto-relacional (ORM), autenticação e gerenciamento de usuários, que podem ser valiosas em microsserviços que exigem manipulação de dados ou integração com bancos de dados relacionais. 
\cite{django}

\subsection{Golang}

Go, também conhecido como Golang, é uma linguagem desenvolvida pelo Google que se destaca pela sua alta performance e simplicidade. A principal vantagem do Go em microsserviços é a sua capacidade de lidar com concorrência de forma eficiente, com seu modelo de \emph{goroutines} e \emph{channels} (canais), que facilita o desenvolvimento de sistemas altamente concorrentes e escaláveis. O Go é especialmente popular em sistemas que exigem alta taxa de transferência e baixos tempos de latência, como sistemas de \emph{streaming} ou microsserviços que lidam com grandes volumes de dados em tempo real. Além disso, o Go possui uma abrangente biblioteca padrão e ótimas bibliotecas desenvolvidas por terceiros, muitas vezes dispensando a necessidade de um \emph{framework} para a linguagem, tornando o microsserviço ainda mais simples.
\cite{golang}

\subsection{JavaScript/TypeScript com Node.js e Express}

Node.js também é muito popular para o desenvolvimento de microsserviços, especialmente em sistemas que exigem alta performance em \emph{I/O} e processamento assíncrono. O Node.js usa um modelo de ciclo de eventos não bloqueante, que é ideal para microsserviços que precisam lidar com uma grande quantidade de requisições simultâneas, como APIs RESTful. Seu ecossistema vasto e a popularidade do JavaScript no desenvolvimento \emph{frontend} também tornam o Node.js uma escolha atraente para equipes que desejam manter uma \emph{stack} unificada em todo o sistema. Além disso, a enorme comunidade de desenvolvedores e a abundância de pacotes disponíveis facilmente instaláveis permitem que os microsserviços sejam desenvolvidos rapidamente e com uma ampla variedade de funcionalidades. O Express, um \emph{framework} minimalista para Node.js, facilita o desenvolvimento de APIs simples e eficientes. 
\cite{expressjs,nodejs}

\subsection{C\# e .NET}

C\# é uma das linguagens mais utilizadas no ecossistema Microsoft e tem se tornado uma escolha popular para o desenvolvimento de microsserviços, principalmente quando combinada com o \emph{framework} .NET Core, que é uma plataforma de desenvolvimento de código aberto, alto desempenho e com suporte a diversos sistemas operacionais. O ASP.NET Core é um subconjunto do .NET focado em criar aplicações web, incluindo APIs RESTful, que são comumente usadas para comunicação entre microsserviços. Desenvolver microsserviços com .NET ou ASP.NET é especialmente adequado para empresas que já operam em ecossistemas Microsoft. Ambos \emph{frameworks} têm uma comunidade ativa e suporte contínuo, o que os torna uma escolha confiável para o desenvolvimento de microsserviços. 
\cite{dotnetcore,aspnetcore}

% \subsection{Ruby e Ruby on Rails}

% Ruby, combinada com o framework Ruby on Rails, é outra escolha popular, especialmente para equipes que precisam de uma solução rápida e eficiente para construir microsserviços. Ruby on Rails é um framework opinativo que segue a filosofia "convention over configuration" (convenção sobre configuração), o que acelera o desenvolvimento e reduz a complexidade do projeto. Embora o Rails tenha sido inicialmente mais associado a aplicações monolíticas, ele também pode ser usado para desenvolver microsserviços, especialmente quando é necessário criar APIs RESTful rapidamente.

% Uma das principais vantagens do Ruby e Ruby on Rails é a rapidez no desenvolvimento, o que o torna ideal para startups ou projetos que precisam ser lançados rapidamente no mercado. Além disso, Ruby possui uma sintaxe simples e legível, o que facilita a manutenção do código. No entanto, a linguagem pode não ser tão eficiente quanto Go ou Java em termos de desempenho, o que pode ser uma desvantagem em sistemas que exigem alta performance.

% \subsection{PHP e Laravel}

% Embora o PHP seja tradicionalmente associado ao desenvolvimento de aplicações web monolíticas, ele também pode ser utilizado com frameworks modernos para construir microsserviços. O Laravel, um dos frameworks PHP mais populares, pode ser adaptado para criar microsserviços ao construir APIs RESTful ou integrar com outras partes de um sistema distribuído. Laravel oferece uma série de ferramentas que facilitam o desenvolvimento de microsserviços, como suporte a autenticação, roteamento flexível e integração com serviços externos.

% O Laravel é uma ótima escolha para equipes que já estão familiarizadas com o ecossistema PHP e que buscam uma solução rápida e eficiente para microsserviços. Ele permite criar sistemas escaláveis por meio de recursos como queues e jobs, que podem ser usados para processamento assíncrono. Além disso, o Laravel também tem forte integração com o Docker e Kubernetes, facilitando a implantação e a escalabilidade de microsserviços. Contudo, embora o Laravel seja muito eficaz para aplicações menores e médias, pode ser desafiador quando se trata de grandes sistemas distribuídos que exigem alta performance em processamento simultâneo, em comparação com outras linguagens como Go ou Java.

% Em arquiteturas de microsserviços, diversas linguagens de programação podem ser usadas, dependendo das necessidades do sistema e da equipe de desenvolvimento. Java é uma das linguagens mais populares para microsserviços, especialmente quando combinada com frameworks como Spring Boot, que facilita a criação de serviços autônomos e escaláveis de forma simples e com pouco código \emph{boilerplate}, além de ser um ecossistema maduro e com suporte a diversas ferramentas prontas para integração, monitoramento e segurança em microsserviços.

% Outra linguagem amplamente utilizada em microsserviços é o Python, que se destaca pela simplicidade e rapidez no desenvolvimento. Python é especialmente útil quando se trabalha com microsserviços baseados em APIs, processamento de dados ou integrações rápidas. Frameworks como Flask e Django permitem a construção de serviços rápidos, enquanto bibliotecas como Celery facilitam o processamento assíncrono. Sua comunidade ativa e a extensa gama de bibliotecas ajudam a resolver muitos problemas comuns em microsserviços de forma rápida e fácil.

% Além disso, linguagens como Go e JavaScript (Node.js) são cada vez mais populares em ambientes de microsserviços. Go é conhecida por sua alta performance, simplicidade e suporte nativo a concorrência, o que a torna ideal para criar serviços altamente escaláveis e eficientes. Já Node.js, com seu modelo de I/O não bloqueante, é ideal para microsserviços que precisam de alta performance em operações de rede e processamento em tempo real. Ambas as linguagens favorecem a criação de microsserviços rápidos e eficientes, com alta escalabilidade, o que as torna bastante atrativas para sistemas distribuídos modernos.

% \footnote{Uma linguagem de programação não pode, por sí só, ser caracterizada como código aberto ou não, mas uma implementação de uma linguagem pode. Para o escopo deste trabalho, todas as implementações mais comuns das linguages de programação citadas são válidas.}

% A programming language isn't in it self open source or not, but an implementation of it might be. Yes, there are open source implementations of Java. Sun's Java implementation (the most popular one), is one of them.

\section{Servidores Web}
Servidores web são responsáveis por receber e tratar requisições, agindo como um \emph{middleware} (meio-termo) entre o consumidor e o provedor. Eles podem disponibilizar diversas funcionalidades úteis na comunicação por meio de requisições, tal como \emph{caching}, compressão de dados, limitação de requisições e balanceamento de carga, assim não havendo necessidade de implementá-las manualmente. Além disso, servidores web também podem ser utilizados como \emph{API Gateways}, técnica crucial para gestão da comunicação entre microsserviços, por centralizar o tráfego e se encarregar de redirecionar requisições para os microsserviços adequados. 

% podendo inclusive (facilmente?) implementar um API Gateway, subconjunto do padrão Gateways

% Diferença entre servidor web e servidor de aplicação: 
% Enquanto os servidores de aplicação executam a lógica de negócio e processam requisições dinâmicas, os servidores web podem atuar como intermediários, otimizando a comunicação entre clientes e serviços. Eles permitem a implementação eficiente de práticas comuns em arquiteturas de microsserviços, como autenticação centralizada, gerenciamento de certificados SSL/TLS e limitação de requisições, reduzindo a carga sobre os servidores de aplicação e melhorando a segurança do sistema.


\subsection{Nginx ou Apache HTTP Server}
O Nginx é um servidor web projetado para lidar com um grande número de conexões simultâneas com consumo eficiente de recursos, tornando-o uma excelente escolha para aplicações escaláveis e dinâmicas. Sua arquitetura baseada em eventos permite melhor desempenho e escalabilidade em comparação com servidores baseados em \emph{threads}, tornando-o ideal para aplicações modernas e de alto tráfego. Além disso, o Nginx pode ser facilmente utilizado como \emph{API Gateway} e \emph{proxy}, técnicas muito pertinentes para auxiliar na comunicação entre microsserviços. \cite{nginx}

% \subsection{Apache HTTP Server}
O Apache HTTP Server, ou apenas Apache, é um servidor web antigo mas muito bem consolidado e muito usado até hoje. Seu suporte a módulos dinâmicos e seu modelo híbrido de processamento permitem ótima adaptação, mas podem resultar em maior consumo de recursos quando comparado ao NGINX em cenários de alto tráfego. Apesar disso, o Apache ainda é uma ótima opção para aplicações tradicionais ou que necessitem de compatibilidade com tecnologias legadas. \cite{nginx-vs-apache}

% \subsection{Caddy}
% TODO:? Já vem com HTTPS configurado e parece bem moderno

\section{Bancos de dados persistentes - SQL e NoSQL}
Como mencionado na \autoref{descentralizacao-dados}, cada microsserviço deve possuir seu próprio modelo de dados independente, podendo usar bancos de dados distintos. Portanto, a escolha do banco de dados adequado é um aspecto importante no projeto de um microsserviço, sendo importante considerar alguns fatores.

Os bancos de dados relacionais (SQL), como MySQL e PostgreSQL, armazenam dados em tabelas estruturadas, utilizando esquemas predefinidos. Eles são ideais para aplicações que requerem alta consistência e integridade dos dados, especialmente quando há muitas relações entre entidades. Esses bancos seguem o modelo ACID (Atomicidade, Consistência, Isolamento e Durabilidade), o que os torna indicados para cenários onde transações complexas e confiabilidade são essenciais. \cite{mongodb-sql-nosql}

Por outro lado, os bancos de dados NoSQL, como MongoDB e Cassandra, oferecem maior flexibilidade ao lidar com dados não estruturados ou semi-estruturados. Eles diferem entre sí em como armazenam informações, podendo ser em documentos JSON (como o MongoDB), em \emph{wide column store} (como o Cassandra), em grafos (como o Neo4j), ou vários outros, sendo a escolha desse tipo de armazenamento também importante. Em contraste com o formato de tabelas estruturadas, esses formatos tendem a facilitar a escalabilidade horizontal e a manipulação de grandes volumes de dados. Bancos de dados NoSQL são especialmente úteis para aplicações que exigem alta disponibilidade e rápida adaptação a mudanças nos dados. \cite{mongodb-sql-nosql}

O modelo de dados deve ser avaliado para determinar se ele é altamente estruturado e relacional, favorecendo SQL, ou se é mais flexível e variável, onde NoSQL pode ser mais apropriado. Além disso, a escalabilidade é um fator essencial: enquanto bancos SQL geralmente escalam melhor verticalmente (aumentando os recursos de um único servidor), bancos NoSQL são melhor projetados para escalabilidade horizontal (adicionando mais servidores conforme a necessidade). \cite{mongodb-sql-nosql}

Outro ponto importante é a escolha entre consistência e disponibilidade. Bancos de dados relacionais enfatizam consistência rigorosa, facilitando que todas as transações sejam processadas corretamente antes de serem confirmadas. Já os bancos NoSQL são mais flexíveis nesse quesito. Por serem projetados para serem descentralizados, podem oferecer ou disponibilidade (caso do Cassandra) ou consistência de dados (caso do MongoDB), \hyperref[teorema-cap]{mas nunca os dois}. Assim sendo, se um microsserviço precisa de transações complexas e forte integridade referencial, um banco de dados SQL tende a ser a melhor opção. \cite{ibm-choosing-database,mongodb-sql-nosql}

Ademais, a decisão entre bancos de dados SQL e NoSQL deve ser feita com base nos requisitos específicos de cada microsserviço. Algumas partes do sistema podem se beneficiar da confiabilidade e estrutura dos bancos relacionais, enquanto outras podem precisar da flexibilidade e escalabilidade dos bancos NoSQL. Uma análise cuidadosa desses aspectos ajudará a construir uma arquitetura de microsserviços mais eficiente e escalável, garantindo o desempenho e a confiabilidade da aplicação.

\section{Bancos de dados em memória - Memcached e Redis}
Outro tipo de banco de dados importante para microsserviços são os em memória, como o Memcached e o Redis, que são ideais para \emph{caching}. O Memcached, apoiado pela Netflix, é simples e eficiente para armazenamento de chave-valor puro, sendo altamente escalável e consumindo pouca memória por não armazenar metadados complexos. No entanto, ele não oferece suporte a estruturas de dados avançadas, persistência, replicação nativa ou recursos como pub/sub. Já o Redis é mais versátil, suportando listas, conjuntos, hashes e permitindo também persistência dos dados no disco, além de replicação e \emph{clustering}, tornando-se útil para aplicações além do cache, como filas e contadores. Enquanto o Memcached tende a ser mais rápido para o propósito puro de \emph{cache} devido à sua leveza, o Redis é mais poderoso e flexível, mas pode exigir mais recursos dependendo do uso. \cite{memcached,redis}

% \subsection{Escalamento de bancos de dados}

% \subsubsection{Replicação de bancos de dados}
% TODO:?

% - ler: https://atlan.com/what-is/database-replication/
% - ler: https://release.com/blog/syncing-databases-how-to-do-it-and-best-practices
% - Aplicação: https://stackoverflow.com/questions/58399450/keeping-databases-in-sync-after-write-update-across-regions-zones
% - ver se tem algum serviço assim na AWS

\section{Integração contínua e Entrega Contínua (CI/CD)}

% GitHub Actions ou GitLab... 

% re-ler: https://martinfowler.com/bliki/ContinuousDelivery.html

% Gitlab: \url{https://about.gitlab.com/topics/ci-cd/} e \url{https://docs.gitlab.com/ci/} e \url{https://gitlab.com/microsservicos1/TesteGitLab/-/learn_gitlab}

% - Reler: https://martinfowler.com/articles/continuousIntegration.html

% Automatizar testes e builds para cada commit em qualquer branch permite feedback rápido, garantindo que o código esteja em um estado consistente em todas as branches, promovendo uma prática de CI eficiente. (Fonte: curso do vinicius)

% Many software tools are available to support implementing CI/CD practices. These CI/CD tools range from repository management such as Github and Bitbucket, Jenkins for build automation, and Selenium and Katalon Studio for test automation.

% What are some common CI/CD tools?
% CI/CD tools can help a team automate their development, deployment, and testing. Some tools specifically handle the integration (CI) side, some manage development and deployment (CD), while others specialize in continuous testing or related functions.
% One of the best known open source tools for CI/CD is the automation server Jenkins. Jenkins is designed to handle anything from a simple CI server to a complete CD hub.
% Deploying Jenkins on Red Hat OpenShift

% Tekton Pipelines is a CI/CD framework for Kubernetes platforms that provides a standard cloud-native CI/CD experience with containers.
% Deploying Jenkins on Red Hat OpenShift

% Beyond Jenkins and Tekton Pipelines, other open source CI/CD tools you may wish to investigate include:
%     Spinnaker, a CD platform built for multicloud environments.
%     GoCD, a CI/CD server with an emphasis on modeling and visualization.
%     Concourse, "an open-source continuous thing-doer."
%     Screwdriver, a build platform designed for CD.

% Teams may also want to consider managed CI/CD tools, which are available from a variety of vendors. The major public cloud providers all offer CI/CD solutions, along with GitLab, CircleCI, Travis CI, Atlassian Bamboo, and many others.
% Additionally, any tool that’s foundational to DevOps is likely to be part of a CI/CD process. Tools for configuration automation (such as Ansible, Chef, and Puppet), container runtimes (such as Docker, rkt, and cri-o), and container orchestration (Kubernetes) aren’t strictly CI/CD tools, but they’ll show up in many CI/CD workflows. \cite{redhat-ci-cd}

\subsection{Sistemas de controle de versão}\label{secao-vcs}
% Usar um sistema de controle de versão é estritamente necessário para se ter integração contínua. 
Um sistema de controle de versão é imprescindível para o desenvolvimento de \emph{software} atualmente e é impossível se ter integração contínua sem um. Os sistemas de controle de versão podem ser categorizados em distribuídos (DVCS), como o Git, ou centralizados (CVCS), como o SVN. Os centralizados mantêm um repositório central onde todas as versões são armazenadas, e os usuários precisam se conectar a ele para obter ou enviar alterações, enquanto nos distribuídos cada usuário possui uma cópia completa do repositório, permitindo trabalho \emph{offline} e melhor gerenciamento de versões. 

Atualmente os distribuídos são o padrão no desenvolvimento de \emph{software}, e pouco se ouve falar dos centralizados. O \textbf{Git} é, empiricamente, o mais popular entre todos os sistemas de controle de versão, e é uma solução elegante e completa para o controle de versão no desenvolvimento de \emph{software}, seja para um único desenvolvedor ou para equipes numerosas.

% \subsection{Gerenciamento de repositórios}
\subsection{Plataformas para CI/CD}
% https://about.gitlab.com/topics/devops-platform/

\subsubsection*{GitHub}
O GitHub é uma plataforma parcial de CI/CD focada no gerenciamento de código-fonte e é extremamente popular, especialmente para projetos de código aberto. Ela oferece uma interface simples e fácil de usar, assim como diversas ferramentas de colaboração e gerenciamento de repositório. Entretanto, não oferece tantas ferramentas quanto o GitLab, então uma solução mais completa de CI/CD requeriria uso de outras ferramentas. Normalmente o GitHub pode ser usado apenas como serviço na nuvem, mas no plano \emph{enterprise} há opções para auto-hospedagem.

% \subsubsection*{Bitbucket}
% O Bitbucket é outra plataforma popular de CI/CD e se destaca por sua integração com outras ferramentas da Atlassian, como o Jira e o Confluence. O Bitbucket permite o uso de repositórios Git e Mercurial (embora o suporte ao Mercurial tenha sido descontinuado em 2020), o que é útil para equipes que ainda mantêm repositórios antigos. O Bitbucket é muito popular entre equipes que já utilizam outras ferramentas Atlassian e preferem uma solução centralizada para todo o ciclo de vida do desenvolvimento.

\subsubsection*{GitLab}
O GitLab é uma plataforma de CI/CD abrangente, oferecendo um conjunto mais completo de ferramentas para o ciclo de vida do desenvolvimento de \emph{software}, desde ferramentas de controle de versão até ferramentas de implantação e monitoramento, simplificando a gestão e a integração de ferramentas por estarem todas em uma única plataforma. Além disso, o GitLab possui funcionalidades embutidas para trabalhar com as ferramentas Kubernetes e Docker, facilitando o uso delas e tornando a plataforma especialmente atraente para quem busca uma solução de CI/CD completa. O GitLab pode ser auto-hospedado ou usado como serviço na nuvem.

% \subsubsection*{Gerenciadores em provedores da nuvem}
% Além das plataformas mencionadas, muitas empresas estão adotando provedores de cloud para gerenciar seus repositórios. Ferramentas como AWS CodeCommit, Azure Repos e Google Cloud Source Repositories oferecem soluções de gerenciamento de código-fonte que são profundamente integradas com os serviços de nuvem dessas plataformas. Por exemplo, o AWS CodeCommit é completamente integrado com o AWS, facilitando a automação do deploy e a utilização de outros serviços da AWS, como Lambda, ECS, e EKS. O Azure Repos, parte do Azure DevOps, oferece uma solução altamente escalável e de integração com ferramentas de DevOps da Microsoft, como Azure Pipelines. O Google Cloud Source Repositories oferece uma experiência semelhante, integrada com outros serviços do Google Cloud Platform, o que pode ser uma vantagem para empresas que já utilizam essas nuvens. Esses provedores de repositórios em nuvem são ideais para organizações que já estão fortemente imersas em um ecossistema de nuvem e preferem uma solução que se integre diretamente com seus outros serviços e infraestrutura de nuvem.

\subsection{Servidores de integração}
% Como mencionado na \autoref{subsecao-servidor-de-integracao}, normalmente a responsabilidade de executar o pipeline de integração é delegada para um servidor de integração, assim tem-se a garantia de que o pipeline será de fato executado e o desenvolvedor não precisará ficar aguardando ela ser executada na máquina dele. 
A escolha do servidor de integração para um microsserviço ou projeto afeta alguns fatores como facilidade de configuração, escalabilidade, suporte a \emph{plugins} (extensões) e integração com outras ferramentas. Aqui são apresentadas 3 das opções mais populares, cada um tendo vantagens e desvantagens dependendo do contexto de uso.

\subsubsection*{GitHub Actions}
O GitHub Actions se destaca pela integração nativa com repositórios do GitHub, tornando o processo de configuração bastante simples para projetos já hospedados no GitHub. Os \emph{pipelines} para um repositório podem ser definidos diretamente nele, usando a linguagem YAML. Sua maior vantagem está na facilidade de uso e na integração com o GitHub, permitindo a execução condicional e configurável do \emph{pipeline} de acordo com eventos do repositório. No entanto, sua desvantagem principal é a dependência do ecossistema GitHub, o que requer uma migração de plataforma para projetos hospedados em outras plataformas de gerenciamento de repositórios.

\subsubsection*{Jenkins}
% TODO:? Citar a documentacao do jenkins?
O Jenkins é um dos sistemas de CI/CD mais bem estabelecidos e flexíveis do mercado. Sendo \emph{open-source} e auto-hospedado, ele oferece uma grande variedade de \emph{plugins} e suporte a diversas ferramentas. Os \emph{pipelines} podem ser definidos para cada projeto usando arquivos jenkinsfile, que são baseados na linguagem Groovy. Sua principal vantagem é a personalização e flexibilidade, podendo ser configurado para praticamente qualquer \emph{pipeline} de CI/CD. No entanto, essa configuração tende a ser mais complexa, exigindo maior conhecimento e manutenção por parte da equipe responsável, além da necessidade de gerenciar sua própria infraestrutura, o que aumenta a complexidade operacional.
% https://faun.pub/github-actions-vs-jenkins-which-should-you-use-d7ba6800e8bb
% https://www.jenkins.io/doc/book/pipeline/jenkinsfile/
% https://geekflare.com/devops/gitlab-ci-vs-jenkins/

\subsubsection*{GitLab CI/CD}
Já o GitLab CI/CD oferece um meio-termo entre a simplicidade do GitHub Actions e a flexibilidade do Jenkins. Ele é integrado ao GitLab, mas não dependente, funcionando nativamente dentro da plataforma porém também podendo ser auto-hospedado, pelo uso da ferramenta GitLab Runner, o que constitui uma de suas maiores vantagens. Semelhante ao GitHub Actions, os \emph{pipelines} podem ser definidos diretamente no repositório do GitLab usando a linguagem YAML. No entanto, para cenários com necessidades bem específicas, pode ser menos aplicável que o Jenkins.
% GitLab CI/CD tem Suporte nativo a Kubernetes e Docker
% GitHub Actions tem Suporte nativo apenas para Docker, mas também pode ser configurado para executar pipelines relacionados a kubernetes
% https://docs.gitlab.com/ci/

% \url{https://about.gitlab.com/topics/ci-cd/continuous-integration-server/}
% \url{https://www.ibm.com/docs/en/integration-bus/10.1?topic=environment-integration-servers}
% \url{https://www.ibm.com/docs/en/app-connect/11.0.0?topic=overview-integration-servers-integration-nodes}

% Listamos abaixo alguns servidores de integração disponíveis no mercado. Isso não é uma lista ordenada por popularidade e algum outro critério. Alguns servidores são opensource, outros não, alguns são pagos ou podem ser alocados na nuvem e outros só existem para nuvem ou instalação local.
% Em geral, não existe uma bala de prata e a melhor ferramenta é aquela que te serve bem:
%     Jenkins (https://jenkins.io/)
%     GoCD (https://www.gocd.org/)
%     Bamboo (https://www.atlassian.com/br/software/bamboo)
%     Travis CI (https://travis-ci.org/)
%     Team City (https://www.jetbrains.com/teamcity/)
%     Circle CI (https://circleci.com/)
%     Gitlab (https://about.gitlab.com/product/continuous-integration/)
%     AWS Code Pipeline https://aws.amazon.com/codepipeline/
%     Azure (https://azure.microsoft.com/pt-br/services/devops/server/)

% >>> PARTE DE TESTES DEIXA PRA LÁ
% \section{Testes}
% % Existem inúmeras coisas que podem ser testadas em um \emph{software}. 
% % Testes não necessariamente requerem uma ferramenta para serem implementados, mas usar uma pode facilitar bastante o trabalho do programador. 
% % Eles podem ser muito abrangentes ou específicos. 
% % Existem diversas ferramentas, então a escolha adequada depende do contexto.

% A escolha de uma feramenta adequada para determinado teste depende do projeto em questão e do tipo de teste a ser executado. Embora muitos testes não exijam o uso de ferramentas além de uma linguagem de programação, elas podem diminuir significativamente o trabalho necessário. Contudo, como existem inúmeras coisas que podem ser testadas em um sistema, desde a eficácia de uma única função até uma funcionalidade abrangendo todo o sistema, apenas são listados aqui algumas das ferramentas para os testes mais comuns em microsserviços.
% % o que torna a seleção de uma ferramenta adequada crucial para otimizar o processo de testes.

% \subsection{Testes de unidade}
% Testes de unidade são mais baixo-nível e as ferramentas usadas para os implementar dependem da linguagem de programação e \emph{framework} em questão. No Java por exemplo, uma biblioteca muito comum para testes de unidade é o JUnit. No python, tem-se o pacote \emph{unittest}. No C\#, tem-se o pacote \emph{xUnit}. No Go, tem-se o pacote \emph{testing}. No JavaScript tem-se a biblioteca \emph{Jest}.

% \subsection{Testes de serviços}
% % Testar um microsserviço pode significar diversas coisas dependendo do que se trata o microsserviço. Pode ser por exemplo testar os endpoints de uma API ou então testar se o serviço está produzindo \emph{logs} como esperado. 
% % Portanto não serão discutidas ferramentas para esses tipos de testes

% \subsubsection*{Testes de APIs}
% [EM PROGRESSO]

% Postman, Insomnia, Thunder Client (integrado ao VSCode), cURL.
% % programar os testes de api em uma linguagem de programação,

% \subsubsection*{Testes de contratos}
% [EM PROGRESSO]

% Pact, Spring Cloud Contract (para o \emph{framework} Spring)

% % \subsubsection*{TestContainers} 
% % Uma biblioteca Java usada para testes de integração com contêineres Docker, permitindo iniciar e parar serviços no Docker para simular cenários do mundo real.

% \subsection{Testes \emph{end-to-end} (ponta a ponta)}
% [EM PROGRESSO]

% - Cypress: Uma poderosa ferramenta de teste de ponta a ponta para aplicativos da web que também pode testar APIs como parte do fluxo de trabalho de ponta a ponta.

% - Selenium: Uma ferramenta para automatizar testes baseados em navegador para microsserviços que são expostos por meio de interfaces da web.

% - Playwright: Uma biblioteca Node.js para automatizar navegadores Chromium, Firefox e WebKit, comumente usada para testes E2E de aplicativos da web.

% - TestCafe: Uma ferramenta para automatizar testes da web, com suporte para testes entre navegadores e execução de testes paralelos.

% - Appium: Uma estrutura para testar aplicativos móveis (nativos, híbridos ou web móvel).
% <<<


\section{Comunicação}

\subsection{RPC - gRPC}
% gRPC é uma ferramenta moderna com alto desempenho que tem ganhado grande popularidade em meio aos praticantes de microsserviços e é considerada um "projeto de incubação" pela Cloud Native Computing Foundation 

% TODO:!!! Melhorar esse lixo ou então só comentar
gRPC é uma ferramenta open-source desenvolvida pelo Google que permite o uso de Remote Procedure Call (RPC) entre sistemas distribuídos. Ele usa o formato \emph{Buffers de protocolo} para trocas de dados com menor consumo de recursos. Uma característica importante do gRPC é seu suporte a \emph{streaming} bidirecional e multiplexação, o que o torna ideal para cenários que exigem comunicação em tempo real e transferências de dados grandes entre serviços. Ele suporta tanto comunicação síncrona quanto assíncrona, oferecendo flexibilidade na interação entre os serviços. 
% O gRPC também usa o HTTP/2, que permite recursos como \emph{streams} de dados multiplexados, compressão de cabeçalhos e gerenciamento eficiente de conexões, tornando-o mais performático do que as APIs REST tradicionais baseadas em HTTP, especialmente em ambientes com baixa latência e alto fluxo. 
Além disso, seu forte sistema de tipagem por meio de Protocol Buffers e suporte embutido para autenticação, balanceamento de carga e descoberta de serviços fazem do gRPC uma ferramenta poderosa para a construção de microsserviços de alto desempenho, escaláveis e seguros. \cite{grpc}

\subsection{Sistemas de mensagens}
Sistemas de mensagens são plataformas que permitem a comunicação entre diferentes componentes ou serviços de um sistema distribuído por meio de mensagens. Eles facilitam a comunicação assíncrona entre sistemas, desacoplando produtores e consumidores de mensagens. Esses sistemas são essenciais para arquiteturas escaláveis, como microserviços, permitindo a transmissão eficiente de dados entre diferentes partes do sistema sem interdependências diretas. Aqui são apontados alguns sistemas de mensagens comumente usados em arquiteturas distribuídas, sendo a escolha entre eles dependente da forma das mensagens, requisitos de escalabilidade e se a solução é auto-hospedada ou com infraestrutura gerenciada.
% CITAR AS DOCUMENTAÇÕES ?

\subsubsection*{RabbitMQ}
% RabbitMQ é um sistema de mensagens que usa o protocolo AMQP para garantir uma comunicação eficiente e confiável entre serviços. Ele é ideal para mensagens de fila, com suporte a padrões como ponto a ponto e publicação/assinatura. Suas vantagens incluem baixa latência, confiabilidade nas mensagens, fácil configuração e suporte a mensagens persistentes. As desvantagens incluem menor escalabilidade em comparação com o Kafka, que é projetado para grandes volumes de dados e eventos em tempo real. Em plataformas na nuvem, RabbitMQ é comparado a soluções como AWS SQS, que oferecem maior escalabilidade e menos sobrecarga de gerenciamento.

O RabbitMQ é um sistema de mensagens baseado no protocolo AMQP que facilita a comunicação assíncrona entre aplicações, oferecendo funcionalidades de publicação e consumo de mensagens. Ele garante confiabilidade na entrega de mensagens e flexibilidade para diversos padrões de troca de mensagens. Contudo, RabbitMQ pode ter limitações de escalabilidade em comparação com sistemas como o Kafka, que são mais adequados para grandes fluxos de dados em tempo real.

\subsubsection*{Apache Kafka}
O Kafka é uma plataforma de \emph{streaming} distribuído de dados, projetada para lidar com grandes volumes de dados em tempo real. Ele é utilizado principalmente para publicar, armazenar e processar fluxos de dados como eventos e logs. O Kafka oferece alta escalabilidade, durabilidade e alta taxa de transferência, suportando casos de uso como rastreamento de atividades de websites, agregação de logs e processamento de fluxos de dados. Com recursos como particionamento e replicação, o Kafka é ideal para arquiteturas de microserviços e sistemas de processamento de dados distribuídos que têm grandes fluxos de dados. \cite{apache-kafka}

\subsubsection{Sistemas de mensagens em provedores na nuvem}
% >> Podia ter uma seção dedicada a comentar sobre provedores em nuvem e suas infinitas ferramentas para desenvolvimento de aplicações.

% Azure Service Bus, Amazon Simple Queue Service, Google Cloud Pub/Sub.
Nos provedores de nuvem AWS, Azure e GCP, tem-se o SQS, Azure Service Bus e Google Pub/Sub, respectivamente. Esses são plataformas como serviços (PAAS) que oferecem sistemas de mensagens totalmente gerenciados, abstraindo assuntos de infraestrutura. Eles são escaláveis e fornecem alta disponibilidade, mas podem oferecer menos opções de configuração em comparação com soluções auto-hospedadas como RabbitMQ e Kafka. Enquanto o RabbitMQ se destaca em enfileiramento de baixa latência e Kafka em \emph{streaming} de eventos em tempo real, soluções em provedores na nuvem tendem a se concentrar em simplicidade, escalabilidade e fácil integração com outros serviços em seus respectivos ecossistemas.

% \subsection{Streaming de Dados}
% Apache Kafka*

% \subsection{APIs}

% \subsubsection{API Gateway}
% nginx (free and paid version), Tyk*, Amazon API Gateway

% \subsubsection{Tipos de API}

% \subsubsubsection*{GraphQL}
% GraphQL 

% \subsubsubsection*{REST}
% REST is not a protocol or a standard, it is an architectural style. During the development phase, API developers can implement REST in a variety of ways.

% Like the other architectural styles, REST also has its guiding principles and constraints. These principles must be satisfied if a service interface has to be referred to as RESTful.

% A Web API (or Web Service) conforming to the REST architectural style is called a REST API (or RESTful API). 

% 6 princípios: https://www.ibm.com/think/topics/graphql-vs-rest-api

% \subsubsection{Documentação}
% TODO:?
% Swagger (free and paid version)

% \subsection*{GraphQL}
% A query language for your API
% GraphQL is a query language for APIs and a runtime for fulfilling those queries with your existing data. GraphQL provides a complete and understandable description of the data in your API, gives clients the power to ask for exactly what they need and nothing more, makes it easier to evolve APIs over time, and enables powerful developer tools. \cite{GraphQL-site}

\section{Conteinerização}

\subsection*{Docker}
O Docker é uma ferramenta de conteinerização amplamente adotada devido à sua facilidade de uso, documentação abrangente e grande comunidade. Ele segue um modelo cliente-servidor, onde um \emph{daemon} (processo em segundo plano) gerencia os contêineres. Os benefícios do Docker incluem configuração simples; implantação e escalamento de contêineres independentemente; grande diversidade de imagens de contêineres disponíveis; e integração com o Kubernetes, uma ferramenta popular e poderosa para gerenciamento de infraestrutura em contêineres. Tais benefícios fazem do Docker uma excelente escolha para o desenvolvimento e implantação de microsserviços. \cite{lxc-vs-docker,podman-vs-docker}

% TODO:? falar sobre o docker-compose

% Os principais casos de uso para o Docker são implantações simplificadas ou automáticas,
% Essa abordagem facilita a orquestração de múltiplos contêineres e a integração com ferramentas como Kubernetes, tornando-o uma opção confiável para aplicações distribuídas. 

% Key benefits of Docker containers

%     Portability: Containers can be moved effortlessly between environments, from development to testing to production, without needing changes, thanks to Docker’s ability to ensure consistency across platforms.
    
%     Ease of use: Docker simplifies container management with intuitive commands like docker run, significantly lowering the learning curve for new users.
    
%     Vast ecosystem: Docker’s extensive library of container images available on Docker Hub and a wide array of management tools support rapid application development and deployment.

% The evolution of Docker from a product that simplified the use of LXC to a comprehensive ecosystem that defines modern containerization practices showcases its transformative impact on the technology landscape. Docker made containers mainstream and established a global community of developers and organizations that continue to innovate on its platform.

% Docker use cases:
% Docker excels in environments where deployment speed and configuration simplicity are paramount, making it an ideal choice for modern software development. Key use cases where Docker demonstrates its strengths include:

%     Streamlined deployment: Docker packages applications into containers along with all their dependencies, ensuring consistent operation across any environment, from development through to production. This eliminates common deployment issues and enhances reliability.
    
%     Microservices architecture: Docker supports the development, deployment, and scaling of microservices independently, enhancing application agility and system resilience. Its integration with Kubernetes further streamlines the orchestration of complex containerized applications, managing their deployment and scaling efficiently.
    
%     CI/CD pipelines: Docker containers facilitate continuous integration and deployment, allowing developers to automate the testing and deployment processes. This approach reduces manual intervention and accelerates release cycles.

%     Extensive image repository and configuration management: Docker Hub offers a vast repository of pre-configured Docker images, simplifying application setup. Docker’s configuration management capabilities ensure consistent container setups, easing maintenance and updates.

% Docker’s utility in supporting rapid development cycles and complex architectures makes it a valuable tool for developers aiming to improve efficiency and operational consistency in their projects.

\subsection*{Podman}
O Podman adota uma arquitetura sem \emph{daemon}, eliminando a necessidade de um serviço central para gerenciar os contêineres. Isso o torna mais seguro, pois permite a execução de contêineres sem privilégios de \emph{root}. O Podman também oferece compatibilidade com a CLI do Docker, facilitando a migração de projetos. Além disso, sua capacidade de gerenciar pods - um grupo de contêineres compartilhando recursos - também o torna uma opção adequada para arquiteturas de microsserviços, especialmente em ambientes com requisitos elevados de segurança. \cite{podman-vs-docker}
% https://medium.com/@supportfly/podman-vs-docker-a-comprehensive-comparison-77b1b41e67e0
% https://www.docker.com/blog/lxc-vs-docker/

\subsection*{LXC}
O LXC (Linux Containers) adota uma abordagem diferente, fornecendo contêineres em nível de sistema operacional, assim permitindo a criação de ambientes virtuais que se comportam como sistemas Linux completos. Isso o torna ideal para casos onde se deseja uma alternativa leve às máquinas virtuais ou um acesso altamente eficiente a recursos do \emph{hardware}, como em aplicações com enormes volumes de dados ou cargas de processamento. Entretanto, não é uma opção comum para implantação de microsserviços, que se beneficiam de contêineres mais isolados e especializados, como os oferecidos pelo Docker e pelo Podman. \cite{lxc-vs-docker}

% O LXD, uma ferramenta contruída em cima do LXC, fornece uma interface mais alto-nível e recursos de gerenciamento adicionais, tornando-o mais comparável às soluções de gerenciamento de máquinas virtuadas baseadas na nuvem.

% \subsection{na nuvem}
% AWS EC2

% \subsection{automático}
% AWS Launch Templates

% \section{Escalamento}
% AWS Auto Scaling Groups

% \subsection{Ferramentas para segurança em APIs}

% Autenticação - Always use secure authentication methods such as OAuth, JWTs, or API Keys. It's not recommended to use basic HTTP authentication as it sends user credentials with each request. It is considered the least secure method.

% Validação de entradas - Métodos de validação de entrada: JSON and XML Schema validation; Regular expressions;  Data type validators available in framework; Minimum and maximum value range check for numerical inputs;  Minimum and maximum length check for strings.

% \subsubsection{Métodos de autenticação}

% API Keys are unique identifiers assigned to clients, which grant them access to an API. They are passed to the server with every request and authenticate the client. They also provide authorization and can be used to identify a user's individual access permissions. API Keys are long alphanumerical strings designed to be almost impossible to guess. They are passed to servers as a query parameter or in an HTTP request header.

% OAuth is a powerful framework that uses tokens to give apps limited access to a user’s data without needing the user’s password. The tokens used are restricted and only allow access to data that the user specified for the particular app. It works by the user(client) first requesting authorization from the resource owner. The user is then given a unique access token from an authorization server used in each request to the resource server.

% Basic HTTP authentication involves the client passing the user’s username and password with every request. This is done using an HTTP Header. Basic HTTP authentication is generally considered the least secure. However, if you decide to use it, ensure you are using an HTTPS connection. If not, data is a risk of being leaked.

% Ferramenta para rate limiting. \cite{rapidAPI-twitter}

\subsection{Gerenciamento de contêineres com Kubernetes}\label{secao-kubernetes}
O Kubernetes é uma plataforma de orquestração de contêineres de código aberto, projetada para facilitar o gerenciamento de serviços e cargas de trabalho que envolvem contêineres, favorecendo alta disponibilidade e escalabilidade de sistemas distribuídos. Com ele, é possível definir como os contêineres devem ser implantados, monitorados e escalados de maneira declarativa e automatizada, facilitando a administração da infraestrutura. \cite{kubernetes}

O Kubernetes pode ter múltiplos \emph{clusters} de servidores onde os contêineres são executados, podendo distribuir cargas de trabalho de maneira eficiente e favorecendo a alta disponibilidade das aplicações. Os principais conceitos do Kubernetes são os \emph{pods}, que agrupam contêineres, os \emph{services}, que intermediam a comunicação interna e/ou externa ao \emph{cluster}, e os \emph{deployments}, que controlam a atualização e escalamento dos contêineres. \cite{kubernetes}

Embora o Kubernetes compartilhe algumas características com plataformas de \emph{Platform as a Service} (PaaS), ele não impõe restrições sobre os tipos de aplicações suportadas, não constrói ou implanta código-fonte automaticamente e não fornece serviços internos, como bancos de dados ou \emph{middlewares}. Diferente de sistemas de orquestração tradicionais, o Kubernetes foca na convergência do estado desejado, favorecendo um ambiente robusto, flexível e adequado para aplicações modernas distribuídas.  \cite{kubernetes}

Dessa forma, o Kubernetes pode ser utilizado em arquiteturas de microsserviços não só por facilitar a administração da infraestrutura, mas também pelas diversas ferramentas valiosas embutidas, como o gerenciamento de configurações, descoberta de serviços, balanceamento de carga, recuperação automática de falhas, alocação dinâmica de volumes e discos, entre outros. Além disso, o Kubernetes suporta diferentes ambientes de execução, como servidores físicos, máquinas virtuais e serviços de nuvem, assim sendo uma solução abrangente e flexível.

% garantindo que cada microsserviço possa ser executado, atualizado e escalado independentemente. Além disso, sua integração com ferramentas de monitoramento, malha de serviços e \emph{pipelines} de CI/CD permite um fluxo de desenvolvimento mais ágil e automatizado, tornando o Kubernetes uma escolha ideal para aplicações baseadas em microsserviços.

% Como os microsserviços são distribuídos, a necessidade de orquestração e escalabilidade é essencial. 


% https://kubernetes.io/docs/concepts/overview/#why-you-need-kubernetes-and-what-can-it-do


% \subsection{Orquestração de contêineres com Docker Swarm}
% [EM PROGRESSO]
% Docker Swarm

% \subsection{Orquestração de contêineres com Conductor}
% Conductor* (https://conductor-oss.github.io/conductor/devguide/concepts/index.html)

\subsubsection*{Kubernetes em provedores na nuvem}
Provedores na núvem como AWS, Azure e GCP oferecem serviços gerenciados de Kubernetes, assim reduzindo ainda mais a complexidade operacional associada à instalação, configuração e manutenção da infraestrutura. Esses serviços facilitam a implementação de clusters Kubernetes, integrando-se com os ecossistemas das respectivas plataformas.

Além disso, os provedores podem oferecer recursos adicionais, como balanceadores de carga gerenciados e integração com sistemas de monitoramento e segurança. A elasticidade proporcionada pela nuvem garante que aplicações com arquitetura de microsserviços possam escalar globalmente sem a necessidade de gerenciar servidores físicos. Ademais, ao usar o Kubernetes em provedores na nuvem a portabilidade ainda é mantida, podendo as aplicações serem facilmente migradas entre provedores ou para infraestrutura híbrida, assim evitando o que é conhecido como \emph{vendor lock-in} (bloqueio de fornecedor).

% Learn About Orchestrating Microservices Using Kubernetes

% The microservices that are running in containers must be able to interact and integrate to provide the required application functionalities. This integration can be achieved through container orchestration.

% Container orchestration enables you to start, stop, and group containers in clusters. It also enables high availability and scaling. Kubernetes is one of the container orchestration platforms that you can use to manage containers.

% After you containerize your microservices, you can deploy them to Oracle Cloud Infrastructure Container Engine for Kubernetes.

% Before you deploy your containerized microservices application to the cloud, you must deploy and test it in a local Kubernetes engine, as follows:

%     Create your microservices application.
%     Build Docker images, to containerize your microservices.
%     Run your microservices in your local Docker engine.
%     Push your container images to a container registry.
%     Deploy and run your microservices in a local Kubernetes engine, such as Minikube.

% After testing the application in a local Kubernetes engine, deploy it to Oracle Cloud Infrastructure Container Engine for Kubernetes as follows:

%     Create a cluster.
%     Download the kubeconfig file.
%     Install kubectl tool on a local device.
%     Prepare the deployment.yaml file.
%     Deploy the microservice to the cluster.
%     Test the microservice.

% The following diagram shows the process for deploying a containerized microservices application to Oracle Cloud Infrastructure Container Engine for Kubernetes. \cite{oracle_microservices}

\section{Observabilidade e Monitoramento}

\subsection{Métricas - Prometheus e Grafana}
Prometheus é uma ferramenta \emph{open-source} de monitoramento e alerta projetada para coletar e analisar dados de séries temporais (métricas). Ele funciona coletando métricas de diversas fontes por meio de \emph{endpoints} instrumentados, armazenando esses dados em sua base de dados de séries temporáis (TSDB) que permite consultas eficientes. O Prometheus permite consultas avançadas usando sua linguagem própria, o PromQL, possibilitando a criação de métricas personalizadas e a definição de alertas e é amplamente usado para monitorar infraestrutura, aplicativos e serviços, especialmente em ambientes distribuidos ou na nuvem. \cite{prometheus-docs}

O Grafana é uma plataforma de visualização que se integra ao Prometheus e a diversas outras fontes de dados. Com ele, é possível construir \emph{dashboards} interativos e personalizados, favorecendo uma visão detalhada do desempenho da aplicação e da infraestrutura, e configurações de alertas e notificações automáticas, facilitando a identificação rápida de problemas.

A combinação do Prometheus com o Grafana é amplamente utilizada em arquiteturas de microsserviços, pois permite monitoramento escalável e descentralizado. Com a instrumentação adequada, é possível monitorar métricas de CPU, memória, latência de requisições, status de serviços, uso de banco de dados e muito mais.

Por serem open-source, essa combinação de ferramentas oferece uma solução robusta e de baixo custo que é amplamente adotada para monitoramento de sistemas. A facilidade de integração com outras tecnologias e a grande comunidade de suporte fazem do Prometheus e do Grafana uma escolha ideal para monitoramento moderno de aplicações.

\subsection{Logging - Grafana Loki}
Grafana Loki, ou apenas Loki, é uma \emph{stack} para agregação e indexação de \emph{logs}, sendo composto por um conjunto de componentes independentes. Ele funciona recebendo um fluxo de \emph{logs} a partir de um agente que os captura da aplicação, e em seguida faz a indexação apenas de metadados deles, como um \emph{label} (rótulo), que apontam para os dados do \emph{log}, que são compactados e armazenados como objeto, assim consumindo pouco armazenamento. Além de consumir pouco armazenamento, o Loki também faz uso eficiente de memória; tem possibilidade para multilocação, ou seja, consegue escutar múltiplas aplicações enviando logs ao mesmo tempo, o que é importante em sistemas distribuídos; é altamente escalável, permitindo diferentes configurações de implantação; e permite que diversas outras ferramentas de observabilidade se conectem com ele. Entretanto, ele usa a própria linguagem de consulta - \emph{LogQL}, o que pode dificultar o aprendizado da ferramenta. Além disso, por indexar apenas metadados, a busca de \emph{logs} por conteúdo é mais dificil, e é preciso que os \emph{logs} sejam bem estruturados e rotulados para ser eficiente. \cite{grafana-loki}

\subsection{Logging - Graylog}
% Graylog é um sistema de gerenciamento de \emph{logs} mais simples do que o Loki.
O Graylog utiliza o Elasticsearch para armazenar os \emph{logs}, que é uma ferramenta de pesquisa e análise de dados distribuída e altamente escalável, otimizada para realizar buscas e consultas rápidas em grandes volumes de dados. Esse modelo é poderoso para consultas complexas em \emph{logs}, mas pode ser mais exigente em termos de configuração e gerenciamento de recursos. O Graylog também possui sua própria interface de usuário para gestão dos \emph{logs}, diferente do Loki que precisa da integração com o Grafana para oferecer uma. Além disso, ele também fornece funcionalidades de alertas, \emph{dashboards} personalizados e visualizações interativas que permitem que os usuários realizem análises complexas dos \emph{logs}. Dessa forma, essa ferramenta é ideal para análise de \emph{logs} complexos e é muito utilizada em ambientes corporativos onde a análise detalhada de \emph{logs} é crítica para a resolução de problemas, auditorias e monitoramento de segurança. \cite{graylog}

\subsection{\emph{Tracing} (rastremanento) - Jaeger}
% https://www.redhat.com/en/topics/microservices/what-is-jaeger
O Jaeger é uma ferramenta \emph{open-source} de rastreamento desenvolvida para monitorar e rastrear fluxos em sistemas distribuídos, oferecendo informações detalhadas sobre cada passo do fluxo, assim facilitando a identificação de gargalos, falhas e latências que podem comprometer a performance do sistema. \cite{jaeger}

Essa ferramenta oferece uma interface gráfica que permite visualizar os rastreamentos de uma forma clara, com diagramas de sequência e linhas do tempo, o que facilita a análise do comportamento dos serviços e a detecção de problemas em pontos específicos da infraestrutura. Ele é compatível com diversas linguagens de programação e é amplamente utilizado em arquiteturas de microsserviços, também podendo ser integrado com outras ferramentas de monitoramento e observabilidade, como o Prometheus e o Grafana, para fazer a correlação de rastreamentos com \emph{logs} e métricas, assim fornecendo uma visão ainda mais ampla do sistema. \cite{jaeger}
  
% Modern tracing tools, such as Jaeger, Zipkin, and OpenTelemetry, help organizations implement distributed tracing efficiently. These tools collect, process, and visualize traces, often integrating with dashboards and monitoring platforms like Grafana or Prometheus for deeper insights. OpenTelemetry, in particular, is gaining traction as a vendor-neutral, open-source standard that unifies telemetry data across logs, metrics, and traces, making it easier to achieve full observability. As distributed systems continue to grow in complexity, tracing has become an essential practice for ensuring system reliability, minimizing downtime, and optimizing application performance.


% Pode haver um serviço dedicado para logs, ou um sidecar de logs (pacote instalável).

% Para manter registros, pode-se desenvolver um serviço dedicado a isso ou utilizar bibliotecas, para poder ser reutilizado onde necessário.

% Logstash*, Sentry, Middleware, Elastic Stack, Graylog*

% \section{Conjunto de ferramentas}
% Seneca*, Google Cloud Functions,

% \section{Framework arquitetural}
% goa*, Kong*

% \section{Plataformas}
% Microsoft Azure is a microservice platform, and it provides a fully automated dynamic infrastructure, SDKs, and runtime containers along with a large portfolio of existing microservices that you can leverage, such as DocumentDb, Redis In-Memory Cache, and Service Bus, to build your own microservices catalog. \cite{Familiar2015}
% AWS
% Uma solução para a sobrecarga na execução de tantos microserviços é a um ambiente de desenvolvimento integrado na linguagem CAOPLE \cite{CAOPLE}. Essa plataforma oferece grande controle sobre a implantação e testagem de microserviços.